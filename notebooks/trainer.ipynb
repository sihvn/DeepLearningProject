{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Custom Densenet-121 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import custom densenet-121 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\121-layer\\\\src', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\notebooks', 'C:\\\\Python312\\\\python312.zip', 'C:\\\\Python312\\\\DLLs', 'C:\\\\Python312\\\\Lib', 'C:\\\\Python312', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv', '', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# import the py file for loading the dataset\n",
    "if \"..\\\\121-layer\\\\src\" not in sys.path:\n",
    "    sys.path.insert(0,r'..\\121-layer\\src')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from custom_densenet import *\n",
    "from preprocessing import *\n",
    "train_dataset, val_dataset,train_loader, val_loader,test_dataset, test_loader= get_data_loaders(data_dir='../raw_data/archive/', label_file='../raw_data/archive/CXR8-selected/Data_Entry_2017_v2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dense_net(\n",
       "  (initial_setup): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (denseblock1): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): transition_block(\n",
       "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock2): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer6): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer7): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer8): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer9): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer10): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer11): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): transition_block(\n",
       "    (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock3): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer6): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer7): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer8): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer9): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer10): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer11): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer12): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer13): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer14): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer15): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer16): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer17): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer18): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer19): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer20): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer21): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer22): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer23): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans3): transition_block(\n",
       "    (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock4): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer6): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer7): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer8): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer9): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer10): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer11): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer12): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer13): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer14): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer15): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (adaptive_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = 2\n",
    "\n",
    "model = dense_net(num_class-1, training = True) #binary so only need one output\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to calculate the F1 score\n",
    "def f1_score(tp, fp, fn):\n",
    "    return 2 * (tp) / (2 * tp + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [20/531], Loss: 0.7814, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.4706\n",
      "Epoch [1/5], Step [40/531], Loss: 0.7502, tp_sum: 4.0000, fp_sum: 8.0000, fn_sum: 1.0000, batch_f1_score: 0.4706\n",
      "Epoch [1/5], Step [60/531], Loss: 0.6245, tp_sum: 7.0000, fp_sum: 1.0000, fn_sum: 2.0000, batch_f1_score: 0.8235\n",
      "Epoch [1/5], Step [80/531], Loss: 0.6633, tp_sum: 7.0000, fp_sum: 4.0000, fn_sum: 1.0000, batch_f1_score: 0.7368\n",
      "Epoch [1/5], Step [100/531], Loss: 0.6975, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 4.0000, batch_f1_score: 0.6667\n",
      "Epoch [1/5], Step [120/531], Loss: 0.7109, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 5.0000, batch_f1_score: 0.4706\n",
      "Epoch [1/5], Step [140/531], Loss: 0.7206, tp_sum: 6.0000, fp_sum: 5.0000, fn_sum: 2.0000, batch_f1_score: 0.6316\n",
      "Epoch [1/5], Step [160/531], Loss: 0.7162, tp_sum: 5.0000, fp_sum: 5.0000, fn_sum: 2.0000, batch_f1_score: 0.5882\n",
      "Epoch [1/5], Step [180/531], Loss: 0.6854, tp_sum: 8.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.7619\n",
      "Epoch [1/5], Step [200/531], Loss: 0.6545, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 2.0000, batch_f1_score: 0.5333\n",
      "Epoch [1/5], Step [220/531], Loss: 0.6976, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6667\n",
      "Epoch [1/5], Step [240/531], Loss: 0.6493, tp_sum: 8.0000, fp_sum: 2.0000, fn_sum: 4.0000, batch_f1_score: 0.7273\n",
      "Epoch [1/5], Step [260/531], Loss: 0.5809, tp_sum: 7.0000, fp_sum: 3.0000, fn_sum: 1.0000, batch_f1_score: 0.7778\n",
      "Epoch [1/5], Step [280/531], Loss: 0.6951, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5000\n",
      "Epoch [1/5], Step [300/531], Loss: 0.7024, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 5.0000, batch_f1_score: 0.6316\n",
      "Epoch [1/5], Step [320/531], Loss: 0.8264, tp_sum: 7.0000, fp_sum: 5.0000, fn_sum: 1.0000, batch_f1_score: 0.7000\n",
      "Epoch [1/5], Step [340/531], Loss: 0.6391, tp_sum: 6.0000, fp_sum: 1.0000, fn_sum: 3.0000, batch_f1_score: 0.7500\n",
      "Epoch [1/5], Step [360/531], Loss: 0.7435, tp_sum: 3.0000, fp_sum: 9.0000, fn_sum: 2.0000, batch_f1_score: 0.3529\n",
      "Epoch [1/5], Step [380/531], Loss: 0.6888, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.6316\n",
      "Epoch [1/5], Step [400/531], Loss: 0.8318, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 3.0000, batch_f1_score: 0.5000\n",
      "Epoch [1/5], Step [420/531], Loss: 0.6745, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 1.0000, batch_f1_score: 0.7059\n",
      "Epoch [1/5], Step [440/531], Loss: 0.7414, tp_sum: 4.0000, fp_sum: 6.0000, fn_sum: 4.0000, batch_f1_score: 0.4444\n",
      "Epoch [1/5], Step [460/531], Loss: 0.6916, tp_sum: 8.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.7273\n",
      "Epoch [1/5], Step [480/531], Loss: 0.6958, tp_sum: 5.0000, fp_sum: 5.0000, fn_sum: 2.0000, batch_f1_score: 0.5882\n",
      "Epoch [1/5], Step [500/531], Loss: 0.7227, tp_sum: 3.0000, fp_sum: 6.0000, fn_sum: 4.0000, batch_f1_score: 0.3750\n",
      "Epoch [1/5], Step [520/531], Loss: 0.6602, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.5882\n",
      "Epoch [2/5], Step [20/531], Loss: 0.7286, tp_sum: 7.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.7000\n",
      "Epoch [2/5], Step [40/531], Loss: 0.7078, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5556\n",
      "Epoch [2/5], Step [60/531], Loss: 0.6660, tp_sum: 8.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.7619\n",
      "Epoch [2/5], Step [80/531], Loss: 0.6425, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6667\n",
      "Epoch [2/5], Step [100/531], Loss: 0.6240, tp_sum: 7.0000, fp_sum: 1.0000, fn_sum: 4.0000, batch_f1_score: 0.7368\n",
      "Epoch [2/5], Step [120/531], Loss: 0.5959, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 1.0000, batch_f1_score: 0.7500\n",
      "Epoch [2/5], Step [140/531], Loss: 0.7040, tp_sum: 3.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.4286\n",
      "Epoch [2/5], Step [160/531], Loss: 0.7249, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 5.0000, batch_f1_score: 0.5263\n",
      "Epoch [2/5], Step [180/531], Loss: 0.7542, tp_sum: 5.0000, fp_sum: 5.0000, fn_sum: 3.0000, batch_f1_score: 0.5556\n",
      "Epoch [2/5], Step [200/531], Loss: 0.6224, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.6667\n",
      "Epoch [2/5], Step [220/531], Loss: 0.6652, tp_sum: 4.0000, fp_sum: 6.0000, fn_sum: 3.0000, batch_f1_score: 0.4706\n",
      "Epoch [2/5], Step [240/531], Loss: 0.6757, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5556\n",
      "Epoch [2/5], Step [260/531], Loss: 0.6413, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 1.0000, batch_f1_score: 0.7059\n",
      "Epoch [2/5], Step [280/531], Loss: 0.8374, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 5.0000, batch_f1_score: 0.2500\n",
      "Epoch [2/5], Step [300/531], Loss: 0.6703, tp_sum: 7.0000, fp_sum: 2.0000, fn_sum: 4.0000, batch_f1_score: 0.7000\n",
      "Epoch [2/5], Step [320/531], Loss: 0.7116, tp_sum: 8.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.7273\n",
      "Epoch [2/5], Step [340/531], Loss: 0.7334, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.4706\n",
      "Epoch [2/5], Step [360/531], Loss: 0.6138, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 1.0000, batch_f1_score: 0.8000\n",
      "Epoch [2/5], Step [380/531], Loss: 0.6860, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5333\n",
      "Epoch [2/5], Step [400/531], Loss: 0.6252, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6250\n",
      "Epoch [2/5], Step [420/531], Loss: 0.6996, tp_sum: 3.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.4615\n",
      "Epoch [2/5], Step [440/531], Loss: 0.6288, tp_sum: 8.0000, fp_sum: 2.0000, fn_sum: 3.0000, batch_f1_score: 0.7619\n",
      "Epoch [2/5], Step [460/531], Loss: 0.7311, tp_sum: 7.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.6364\n",
      "Epoch [2/5], Step [480/531], Loss: 0.6698, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5000\n",
      "Epoch [2/5], Step [500/531], Loss: 0.7236, tp_sum: 5.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.5263\n",
      "Epoch [2/5], Step [520/531], Loss: 0.6786, tp_sum: 3.0000, fp_sum: 5.0000, fn_sum: 2.0000, batch_f1_score: 0.4615\n",
      "Epoch [3/5], Step [20/531], Loss: 0.6151, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 0.0000, batch_f1_score: 0.7500\n",
      "Epoch [3/5], Step [40/531], Loss: 0.7307, tp_sum: 3.0000, fp_sum: 7.0000, fn_sum: 3.0000, batch_f1_score: 0.3750\n",
      "Epoch [3/5], Step [60/531], Loss: 0.7457, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 2.0000, batch_f1_score: 0.5333\n",
      "Epoch [3/5], Step [80/531], Loss: 0.5710, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 1.0000, batch_f1_score: 0.8000\n",
      "Epoch [3/5], Step [100/531], Loss: 0.6795, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5333\n",
      "Epoch [3/5], Step [120/531], Loss: 0.7077, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.6316\n",
      "Epoch [3/5], Step [140/531], Loss: 0.6989, tp_sum: 2.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.3077\n",
      "Epoch [3/5], Step [160/531], Loss: 0.6777, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5333\n",
      "Epoch [3/5], Step [180/531], Loss: 0.6606, tp_sum: 7.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.7000\n",
      "Epoch [3/5], Step [200/531], Loss: 0.6808, tp_sum: 7.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.7000\n",
      "Epoch [3/5], Step [220/531], Loss: 0.6611, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.4615\n",
      "Epoch [3/5], Step [240/531], Loss: 0.7028, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.6316\n",
      "Epoch [3/5], Step [260/531], Loss: 0.7025, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6667\n",
      "Epoch [3/5], Step [280/531], Loss: 0.6665, tp_sum: 7.0000, fp_sum: 2.0000, fn_sum: 4.0000, batch_f1_score: 0.7000\n",
      "Epoch [3/5], Step [300/531], Loss: 0.7235, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.6316\n",
      "Epoch [3/5], Step [320/531], Loss: 0.6820, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 2.0000, batch_f1_score: 0.3077\n",
      "Epoch [3/5], Step [340/531], Loss: 0.7632, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 5.0000, batch_f1_score: 0.5263\n",
      "Epoch [3/5], Step [360/531], Loss: 0.6938, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.5556\n",
      "Epoch [3/5], Step [380/531], Loss: 0.5998, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6250\n",
      "Epoch [3/5], Step [400/531], Loss: 0.7697, tp_sum: 3.0000, fp_sum: 5.0000, fn_sum: 6.0000, batch_f1_score: 0.3529\n",
      "Epoch [3/5], Step [420/531], Loss: 0.7197, tp_sum: 3.0000, fp_sum: 6.0000, fn_sum: 1.0000, batch_f1_score: 0.4615\n",
      "Epoch [3/5], Step [440/531], Loss: 0.7252, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.6000\n",
      "Epoch [3/5], Step [460/531], Loss: 0.7638, tp_sum: 3.0000, fp_sum: 7.0000, fn_sum: 2.0000, batch_f1_score: 0.4000\n",
      "Epoch [3/5], Step [480/531], Loss: 0.5758, tp_sum: 7.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.7368\n",
      "Epoch [3/5], Step [500/531], Loss: 0.7829, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.4706\n",
      "Epoch [3/5], Step [520/531], Loss: 0.7181, tp_sum: 7.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.7000\n",
      "Epoch [4/5], Step [20/531], Loss: 0.6697, tp_sum: 6.0000, fp_sum: 5.0000, fn_sum: 2.0000, batch_f1_score: 0.6316\n",
      "Epoch [4/5], Step [40/531], Loss: 0.7381, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.6000\n",
      "Epoch [4/5], Step [60/531], Loss: 0.5612, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 2.0000, batch_f1_score: 0.7500\n",
      "Epoch [4/5], Step [80/531], Loss: 0.6335, tp_sum: 4.0000, fp_sum: 6.0000, fn_sum: 0.0000, batch_f1_score: 0.5714\n",
      "Epoch [4/5], Step [100/531], Loss: 0.6877, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.6316\n",
      "Epoch [4/5], Step [120/531], Loss: 0.6889, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.6316\n",
      "Epoch [4/5], Step [140/531], Loss: 0.6434, tp_sum: 7.0000, fp_sum: 2.0000, fn_sum: 4.0000, batch_f1_score: 0.7000\n",
      "Epoch [4/5], Step [160/531], Loss: 0.7086, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.4706\n",
      "Epoch [4/5], Step [180/531], Loss: 0.7142, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 2.0000, batch_f1_score: 0.3077\n",
      "Epoch [4/5], Step [200/531], Loss: 0.6445, tp_sum: 7.0000, fp_sum: 2.0000, fn_sum: 2.0000, batch_f1_score: 0.7778\n",
      "Epoch [4/5], Step [220/531], Loss: 0.5916, tp_sum: 8.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.7619\n",
      "Epoch [4/5], Step [240/531], Loss: 0.6287, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5333\n",
      "Epoch [4/5], Step [260/531], Loss: 0.6908, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5000\n",
      "Epoch [4/5], Step [280/531], Loss: 0.6106, tp_sum: 8.0000, fp_sum: 2.0000, fn_sum: 1.0000, batch_f1_score: 0.8421\n",
      "Epoch [4/5], Step [300/531], Loss: 0.6452, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6667\n",
      "Epoch [4/5], Step [320/531], Loss: 0.6902, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 2.0000, batch_f1_score: 0.5333\n",
      "Epoch [4/5], Step [340/531], Loss: 0.6733, tp_sum: 4.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.6154\n",
      "Epoch [4/5], Step [360/531], Loss: 0.6944, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.6250\n",
      "Epoch [4/5], Step [380/531], Loss: 0.6767, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.6316\n",
      "Epoch [4/5], Step [400/531], Loss: 0.6278, tp_sum: 7.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.7368\n",
      "Epoch [4/5], Step [420/531], Loss: 0.6830, tp_sum: 5.0000, fp_sum: 6.0000, fn_sum: 2.0000, batch_f1_score: 0.5556\n",
      "Epoch [4/5], Step [440/531], Loss: 0.7209, tp_sum: 8.0000, fp_sum: 2.0000, fn_sum: 3.0000, batch_f1_score: 0.7619\n",
      "Epoch [4/5], Step [460/531], Loss: 0.6758, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5556\n",
      "Epoch [4/5], Step [480/531], Loss: 0.7369, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.6000\n",
      "Epoch [4/5], Step [500/531], Loss: 0.6455, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.6250\n",
      "Epoch [4/5], Step [520/531], Loss: 0.5760, tp_sum: 7.0000, fp_sum: 2.0000, fn_sum: 2.0000, batch_f1_score: 0.7778\n",
      "Epoch [5/5], Step [20/531], Loss: 0.6508, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.5882\n",
      "Epoch [5/5], Step [40/531], Loss: 0.7003, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.6667\n",
      "Epoch [5/5], Step [60/531], Loss: 0.7202, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 5.0000, batch_f1_score: 0.6316\n",
      "Epoch [5/5], Step [80/531], Loss: 0.6614, tp_sum: 5.0000, fp_sum: 2.0000, fn_sum: 6.0000, batch_f1_score: 0.5556\n",
      "Epoch [5/5], Step [100/531], Loss: 0.7100, tp_sum: 4.0000, fp_sum: 6.0000, fn_sum: 3.0000, batch_f1_score: 0.4706\n",
      "Epoch [5/5], Step [120/531], Loss: 0.6872, tp_sum: 3.0000, fp_sum: 6.0000, fn_sum: 4.0000, batch_f1_score: 0.3750\n",
      "Epoch [5/5], Step [140/531], Loss: 0.6963, tp_sum: 10.0000, fp_sum: 0.0000, fn_sum: 5.0000, batch_f1_score: 0.8000\n",
      "Epoch [5/5], Step [160/531], Loss: 0.6739, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5333\n",
      "Epoch [5/5], Step [180/531], Loss: 0.6181, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 1.0000, batch_f1_score: 0.7500\n",
      "Epoch [5/5], Step [200/531], Loss: 0.6611, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.6316\n",
      "Epoch [5/5], Step [220/531], Loss: 0.7303, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 2.0000, batch_f1_score: 0.3077\n",
      "Epoch [5/5], Step [240/531], Loss: 0.7213, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.4706\n",
      "Epoch [5/5], Step [260/531], Loss: 0.6932, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.6000\n",
      "Epoch [5/5], Step [280/531], Loss: 0.7439, tp_sum: 5.0000, fp_sum: 5.0000, fn_sum: 3.0000, batch_f1_score: 0.5556\n",
      "Epoch [5/5], Step [300/531], Loss: 0.5573, tp_sum: 7.0000, fp_sum: 3.0000, fn_sum: 1.0000, batch_f1_score: 0.7778\n",
      "Epoch [5/5], Step [320/531], Loss: 0.7561, tp_sum: 2.0000, fp_sum: 8.0000, fn_sum: 3.0000, batch_f1_score: 0.2667\n",
      "Epoch [5/5], Step [340/531], Loss: 0.7118, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 1.0000, batch_f1_score: 0.5714\n",
      "Epoch [5/5], Step [360/531], Loss: 0.7019, tp_sum: 5.0000, fp_sum: 6.0000, fn_sum: 1.0000, batch_f1_score: 0.5882\n",
      "Epoch [5/5], Step [380/531], Loss: 0.7314, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5556\n",
      "Epoch [5/5], Step [400/531], Loss: 0.7192, tp_sum: 2.0000, fp_sum: 6.0000, fn_sum: 2.0000, batch_f1_score: 0.3333\n",
      "Epoch [5/5], Step [420/531], Loss: 0.6560, tp_sum: 7.0000, fp_sum: 4.0000, fn_sum: 1.0000, batch_f1_score: 0.7368\n",
      "Epoch [5/5], Step [440/531], Loss: 0.6436, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 1.0000, batch_f1_score: 0.6667\n",
      "Epoch [5/5], Step [460/531], Loss: 0.7125, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5882\n",
      "Epoch [5/5], Step [480/531], Loss: 0.6264, tp_sum: 6.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.6667\n",
      "Epoch [5/5], Step [500/531], Loss: 0.6965, tp_sum: 5.0000, fp_sum: 5.0000, fn_sum: 3.0000, batch_f1_score: 0.5556\n",
      "Epoch [5/5], Step [520/531], Loss: 0.6872, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 3.0000, batch_f1_score: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n",
    "\n",
    "# Create a TensorBoard writer\n",
    "model_name = \"custom_dnet_binary_by_img_count_lr_1e-4\"\n",
    "writer = SummaryWriter(log_dir=f\".//runs//{model_name}_train\")\n",
    "val_writer = SummaryWriter(log_dir=f\".//runs//{model_name}_val\")\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 5\n",
    "bs = train_loader.batch_size\n",
    "conf_threshold = 1/num_class\n",
    "lossMIN = 100000\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    ## train\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).unsqueeze(1).float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step(loss)\n",
    "\n",
    "        if (i + 1) % 20 == 0:\n",
    "            # calculate statistics\n",
    "            tp_array = [0 for x in range(num_class)]\n",
    "            fp_array = [0 for x in range(num_class)]\n",
    "            fn_array = [0 for x in range(num_class)]\n",
    "            pred_labels = (outputs > conf_threshold)\n",
    "            tp_array += sum(torch.logical_and(pred_labels, labels))\n",
    "            fp_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), pred_labels))\n",
    "            fn_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), labels))\n",
    "            \n",
    "            writer.add_scalar('Loss/img_count', loss, epoch * len(train_dataset) + i * bs)\n",
    "            writer.add_scalar('TP_Sum/img_count', sum(tp_array), epoch * len(train_dataset) + i * bs)\n",
    "            writer.add_scalar('FP_Sum/img_count', sum(fp_array), epoch * len(train_dataset) + i * bs)\n",
    "            writer.add_scalar('FN_Sum/img_count', sum(fn_array), epoch * len(train_dataset) + i * bs)\n",
    "            writer.add_scalar('F1_Score/img_count', f1_score(sum(tp_array), sum(fp_array), sum(fn_array)), epoch * len(train_dataset) + i * bs)\n",
    "            print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, tp_sum: {:.4f}, fp_sum: {:.4f}, fn_sum: {:.4f}, batch_f1_score: {:.4f}\".format(epoch + 1, \\\n",
    "                                                                     n_epochs, \\\n",
    "                                                                     i + 1, \\\n",
    "                                                                     len(train_loader), \\\n",
    "                                                                     loss,\\\n",
    "                                                                     sum(tp_array), \\\n",
    "                                                                     sum(fp_array),\\\n",
    "                                                                     sum(fn_array),\\\n",
    "                                                                     f1_score(sum(tp_array), sum(fp_array), sum(fn_array))))\n",
    "        # print(\"outputs\\n\", outputs)\n",
    "        # print(\"pred_labels\\n\", pred_labels)\n",
    "        # print(\"actual labels\\n\", labels)\n",
    "\n",
    "        if loss < lossMIN:\n",
    "                lossMIN = loss    \n",
    "                torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, r'./dnet_models/m-' + model_name + '.pth.tar')\n",
    "\n",
    "    ## val\n",
    "    model.eval()\n",
    "    ## calculation on the validation side of things\n",
    "    tp_array = [0 for x in range(num_class)]\n",
    "    fp_array = [0 for x in range(num_class)]\n",
    "    fn_array = [0 for x in range(num_class)]\n",
    "\n",
    "    for i, (images, labels) in enumerate(val_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).unsqueeze(1).float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        pred_labels = (outputs > conf_threshold)\n",
    "        tp_array += sum(torch.logical_and(pred_labels, labels))\n",
    "        fp_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), pred_labels))\n",
    "        fn_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), labels))\n",
    "\n",
    "    ## write to tensorboard    \n",
    "    val_writer.add_scalar('Loss/img_count', loss, len(train_dataset) * (epoch+1))\n",
    "    val_writer.add_scalar('TP_Sum/img_count', sum(tp_array), len(train_dataset) * (epoch+1))\n",
    "    val_writer.add_scalar('FP_Sum/img_count', sum(fp_array), len(train_dataset) * (epoch+1))\n",
    "    val_writer.add_scalar('FN_Sum/img_count', sum(fn_array), len(train_dataset) * (epoch+1))\n",
    "    val_writer.add_scalar('F1_Score/img_count', f1_score(sum(tp_array), sum(fp_array), sum(fn_array)), len(train_dataset) * (epoch+1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
