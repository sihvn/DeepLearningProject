{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Custom Densenet-121 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import custom densenet-121 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\121-layer\\\\src', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\notebooks', 'C:\\\\Python312\\\\python312.zip', 'C:\\\\Python312\\\\DLLs', 'C:\\\\Python312\\\\Lib', 'C:\\\\Python312', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv', '', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# import the py file for loading the dataset\n",
    "if \"..\\\\121-layer\\\\src\" not in sys.path:\n",
    "    sys.path.insert(0,r'..\\121-layer\\src')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Size: 8484\n",
      "Validation Dataset Size: 1060\n",
      "Test Dataset Size: 1060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from custom_densenet import *\n",
    "from preprocessing import *\n",
    "from train_densenet import *\n",
    "train_dataset, val_dataset,train_loader, val_loader,test_dataset, test_loader= get_data_loaders(data_dir='../raw_data/archive/', label_file='../raw_data/archive/CXR8-selected/Data_Entry_2017_v2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, yin train_loader:\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "#     print(z)\n",
    "#     print(z.dtype)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dense_net_plus_one(\n",
       "  (initial_setup): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (denseblock0): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans0): transition_block(\n",
       "    (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock1): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): transition_block(\n",
       "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock2): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer6): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer7): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer8): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer9): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer10): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer11): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): transition_block(\n",
       "    (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock3): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer6): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer7): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer8): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer9): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer10): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer11): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer12): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer13): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer14): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer15): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer16): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer17): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer18): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer19): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer20): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer21): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer22): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer23): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans3): transition_block(\n",
       "    (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock4): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer6): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer7): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer8): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer9): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer10): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer11): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer12): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer13): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer14): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer15): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (adaptive_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "## custom implementation\n",
    "\n",
    "model = dense_net_plus_one(num_class-1, training = True) #binary so only need one output\n",
    "model.to(device)\n",
    "\n",
    "## official implementation\n",
    "# import torchvision.models.densenet\n",
    "# import torchvision\n",
    "\n",
    "# model = torchvision.models.densenet121(weights='DenseNet121_Weights.DEFAULT')\n",
    "# kernelCount = model.classifier.in_features\n",
    "# model.classifier = nn.Sequential(nn.Linear(kernelCount, num_class -1), nn.Sigmoid())\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/531], Loss: 0.7065, tp_sum: 2.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.3636\n",
      "Epoch [1/5], Step [21/531], Loss: 0.6890, tp_sum: 6.0000, fp_sum: 1.0000, fn_sum: 6.0000, batch_f1_score: 0.6316\n",
      "Epoch [1/5], Step [41/531], Loss: 0.6683, tp_sum: 2.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.3636\n",
      "Epoch [1/5], Step [61/531], Loss: 0.7279, tp_sum: 3.0000, fp_sum: 3.0000, fn_sum: 6.0000, batch_f1_score: 0.4000\n",
      "Epoch [1/5], Step [81/531], Loss: 0.7102, tp_sum: 3.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.4615\n",
      "Epoch [1/5], Step [101/531], Loss: 0.7004, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5333\n",
      "Epoch [1/5], Step [121/531], Loss: 0.7747, tp_sum: 2.0000, fp_sum: 6.0000, fn_sum: 6.0000, batch_f1_score: 0.2500\n",
      "Epoch [1/5], Step [141/531], Loss: 0.6718, tp_sum: 2.0000, fp_sum: 6.0000, fn_sum: 3.0000, batch_f1_score: 0.3077\n",
      "Epoch [1/5], Step [161/531], Loss: 0.7916, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 4.0000, batch_f1_score: 0.2667\n",
      "Epoch [1/5], Step [181/531], Loss: 0.7108, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.5556\n",
      "Epoch [1/5], Step [201/531], Loss: 0.6434, tp_sum: 6.0000, fp_sum: 1.0000, fn_sum: 3.0000, batch_f1_score: 0.7500\n",
      "Epoch [1/5], Step [221/531], Loss: 0.8037, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 5.0000, batch_f1_score: 0.4444\n",
      "Epoch [1/5], Step [241/531], Loss: 0.6889, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5000\n",
      "Epoch [1/5], Step [261/531], Loss: 0.7103, tp_sum: 2.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.3636\n",
      "Epoch [1/5], Step [281/531], Loss: 0.6896, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.4615\n",
      "Epoch [1/5], Step [301/531], Loss: 0.7307, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.6316\n",
      "Epoch [1/5], Step [321/531], Loss: 0.6958, tp_sum: 4.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.5714\n",
      "Epoch [1/5], Step [341/531], Loss: 0.7122, tp_sum: 1.0000, fp_sum: 6.0000, fn_sum: 5.0000, batch_f1_score: 0.1538\n",
      "Epoch [1/5], Step [361/531], Loss: 0.6474, tp_sum: 5.0000, fp_sum: 0.0000, fn_sum: 6.0000, batch_f1_score: 0.6250\n",
      "Epoch [1/5], Step [381/531], Loss: 0.7167, tp_sum: 2.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.3333\n",
      "Epoch [1/5], Step [401/531], Loss: 0.7580, tp_sum: 4.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.5000\n",
      "Epoch [1/5], Step [421/531], Loss: 0.7266, tp_sum: 3.0000, fp_sum: 6.0000, fn_sum: 3.0000, batch_f1_score: 0.4000\n",
      "Epoch [1/5], Step [441/531], Loss: 0.7094, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5556\n",
      "Epoch [1/5], Step [461/531], Loss: 0.8276, tp_sum: 1.0000, fp_sum: 5.0000, fn_sum: 6.0000, batch_f1_score: 0.1538\n",
      "Epoch [1/5], Step [481/531], Loss: 0.7210, tp_sum: 7.0000, fp_sum: 2.0000, fn_sum: 6.0000, batch_f1_score: 0.6364\n",
      "Epoch [1/5], Step [501/531], Loss: 0.7238, tp_sum: 5.0000, fp_sum: 2.0000, fn_sum: 8.0000, batch_f1_score: 0.5000\n",
      "Epoch [1/5], Step [521/531], Loss: 0.8452, tp_sum: 2.0000, fp_sum: 5.0000, fn_sum: 7.0000, batch_f1_score: 0.2500\n",
      "Epoch [2/5], Step [1/531], Loss: 0.7529, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 5.0000, batch_f1_score: 0.4000\n",
      "Epoch [2/5], Step [21/531], Loss: 0.6084, tp_sum: 5.0000, fp_sum: 2.0000, fn_sum: 3.0000, batch_f1_score: 0.6667\n",
      "Epoch [2/5], Step [41/531], Loss: 0.6867, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 4.0000, batch_f1_score: 0.6667\n",
      "Epoch [2/5], Step [61/531], Loss: 0.6884, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5000\n",
      "Epoch [2/5], Step [81/531], Loss: 0.7094, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.5556\n",
      "Epoch [2/5], Step [101/531], Loss: 0.7476, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 5.0000, batch_f1_score: 0.4706\n",
      "Epoch [2/5], Step [121/531], Loss: 0.6635, tp_sum: 6.0000, fp_sum: 1.0000, fn_sum: 4.0000, batch_f1_score: 0.7059\n",
      "Epoch [2/5], Step [141/531], Loss: 0.6347, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 1.0000, batch_f1_score: 0.7500\n",
      "Epoch [2/5], Step [161/531], Loss: 0.6991, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 5.0000, batch_f1_score: 0.4000\n",
      "Epoch [2/5], Step [181/531], Loss: 0.7517, tp_sum: 4.0000, fp_sum: 2.0000, fn_sum: 7.0000, batch_f1_score: 0.4706\n",
      "Epoch [2/5], Step [201/531], Loss: 0.7803, tp_sum: 3.0000, fp_sum: 6.0000, fn_sum: 5.0000, batch_f1_score: 0.3529\n",
      "Epoch [2/5], Step [221/531], Loss: 0.8082, tp_sum: 1.0000, fp_sum: 5.0000, fn_sum: 8.0000, batch_f1_score: 0.1333\n",
      "Epoch [2/5], Step [241/531], Loss: 0.6919, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.4286\n",
      "Epoch [2/5], Step [261/531], Loss: 0.6099, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 1.0000, batch_f1_score: 0.6667\n",
      "Epoch [2/5], Step [281/531], Loss: 0.6922, tp_sum: 3.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.5000\n",
      "Epoch [2/5], Step [301/531], Loss: 0.7218, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 6.0000, batch_f1_score: 0.5714\n",
      "Epoch [2/5], Step [321/531], Loss: 0.5794, tp_sum: 6.0000, fp_sum: 1.0000, fn_sum: 3.0000, batch_f1_score: 0.7500\n",
      "Epoch [2/5], Step [341/531], Loss: 0.8254, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 6.0000, batch_f1_score: 0.4211\n",
      "Epoch [2/5], Step [361/531], Loss: 0.7845, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 6.0000, batch_f1_score: 0.4444\n",
      "Epoch [2/5], Step [381/531], Loss: 0.7539, tp_sum: 2.0000, fp_sum: 4.0000, fn_sum: 5.0000, batch_f1_score: 0.3077\n",
      "Epoch [2/5], Step [401/531], Loss: 0.6842, tp_sum: 3.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.4615\n",
      "Epoch [2/5], Step [421/531], Loss: 0.7242, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.5882\n",
      "Epoch [2/5], Step [441/531], Loss: 0.6569, tp_sum: 5.0000, fp_sum: 2.0000, fn_sum: 3.0000, batch_f1_score: 0.6667\n",
      "Epoch [2/5], Step [461/531], Loss: 0.7710, tp_sum: 3.0000, fp_sum: 3.0000, fn_sum: 7.0000, batch_f1_score: 0.3750\n",
      "Epoch [2/5], Step [481/531], Loss: 0.7810, tp_sum: 3.0000, fp_sum: 3.0000, fn_sum: 8.0000, batch_f1_score: 0.3529\n",
      "Epoch [2/5], Step [501/531], Loss: 0.6873, tp_sum: 3.0000, fp_sum: 5.0000, fn_sum: 3.0000, batch_f1_score: 0.4286\n",
      "Epoch [2/5], Step [521/531], Loss: 0.7586, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 3.0000, batch_f1_score: 0.5000\n",
      "Epoch [3/5], Step [1/531], Loss: 0.7002, tp_sum: 2.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.3077\n",
      "Epoch [3/5], Step [21/531], Loss: 0.6908, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 6.0000, batch_f1_score: 0.5263\n",
      "Epoch [3/5], Step [41/531], Loss: 0.7525, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.4615\n",
      "Epoch [3/5], Step [61/531], Loss: 0.6486, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.5000\n",
      "Epoch [3/5], Step [81/531], Loss: 0.6338, tp_sum: 6.0000, fp_sum: 1.0000, fn_sum: 4.0000, batch_f1_score: 0.7059\n",
      "Epoch [3/5], Step [101/531], Loss: 0.7384, tp_sum: 5.0000, fp_sum: 5.0000, fn_sum: 3.0000, batch_f1_score: 0.5556\n",
      "Epoch [3/5], Step [121/531], Loss: 0.6801, tp_sum: 7.0000, fp_sum: 0.0000, fn_sum: 6.0000, batch_f1_score: 0.7000\n",
      "Epoch [3/5], Step [141/531], Loss: 0.7543, tp_sum: 4.0000, fp_sum: 3.0000, fn_sum: 6.0000, batch_f1_score: 0.4706\n",
      "Epoch [3/5], Step [161/531], Loss: 0.6900, tp_sum: 5.0000, fp_sum: 2.0000, fn_sum: 7.0000, batch_f1_score: 0.5263\n",
      "Epoch [3/5], Step [181/531], Loss: 0.7127, tp_sum: 1.0000, fp_sum: 6.0000, fn_sum: 6.0000, batch_f1_score: 0.1429\n",
      "Epoch [3/5], Step [201/531], Loss: 0.6134, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 1.0000, batch_f1_score: 0.6154\n",
      "Epoch [3/5], Step [221/531], Loss: 0.8666, tp_sum: 4.0000, fp_sum: 6.0000, fn_sum: 5.0000, batch_f1_score: 0.4211\n",
      "Epoch [3/5], Step [241/531], Loss: 0.6990, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.4615\n",
      "Epoch [3/5], Step [261/531], Loss: 0.6731, tp_sum: 7.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.7368\n",
      "Epoch [3/5], Step [281/531], Loss: 0.7567, tp_sum: 4.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.5000\n",
      "Epoch [3/5], Step [301/531], Loss: 0.7715, tp_sum: 2.0000, fp_sum: 5.0000, fn_sum: 2.0000, batch_f1_score: 0.3636\n",
      "Epoch [3/5], Step [321/531], Loss: 0.7280, tp_sum: 2.0000, fp_sum: 6.0000, fn_sum: 6.0000, batch_f1_score: 0.2500\n",
      "Epoch [3/5], Step [341/531], Loss: 0.6613, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5333\n",
      "Epoch [3/5], Step [361/531], Loss: 0.6890, tp_sum: 4.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.6154\n",
      "Epoch [3/5], Step [381/531], Loss: 0.7054, tp_sum: 3.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.4000\n",
      "Epoch [3/5], Step [401/531], Loss: 0.7684, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 6.0000, batch_f1_score: 0.3750\n",
      "Epoch [3/5], Step [421/531], Loss: 0.6016, tp_sum: 7.0000, fp_sum: 2.0000, fn_sum: 1.0000, batch_f1_score: 0.8235\n",
      "Epoch [3/5], Step [441/531], Loss: 0.7241, tp_sum: 2.0000, fp_sum: 6.0000, fn_sum: 4.0000, batch_f1_score: 0.2857\n",
      "Epoch [3/5], Step [461/531], Loss: 0.6300, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.6667\n",
      "Epoch [3/5], Step [481/531], Loss: 0.6630, tp_sum: 5.0000, fp_sum: 2.0000, fn_sum: 4.0000, batch_f1_score: 0.6250\n",
      "Epoch [3/5], Step [501/531], Loss: 0.7071, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.5556\n",
      "Epoch [3/5], Step [521/531], Loss: 0.7006, tp_sum: 3.0000, fp_sum: 3.0000, fn_sum: 2.0000, batch_f1_score: 0.5455\n",
      "Epoch [4/5], Step [1/531], Loss: 0.7641, tp_sum: 5.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.5263\n",
      "Epoch [4/5], Step [21/531], Loss: 0.6625, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5333\n",
      "Epoch [4/5], Step [41/531], Loss: 0.7423, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.4286\n",
      "Epoch [4/5], Step [61/531], Loss: 0.7175, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.5556\n",
      "Epoch [4/5], Step [81/531], Loss: 0.6675, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.5556\n",
      "Epoch [4/5], Step [101/531], Loss: 0.6793, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6250\n",
      "Epoch [4/5], Step [121/531], Loss: 0.7391, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 3.0000, batch_f1_score: 0.2857\n",
      "Epoch [4/5], Step [141/531], Loss: 0.7132, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 1.0000, batch_f1_score: 0.3333\n",
      "Epoch [4/5], Step [161/531], Loss: 0.7554, tp_sum: 2.0000, fp_sum: 6.0000, fn_sum: 3.0000, batch_f1_score: 0.3077\n",
      "Epoch [4/5], Step [181/531], Loss: 0.7170, tp_sum: 3.0000, fp_sum: 5.0000, fn_sum: 6.0000, batch_f1_score: 0.3529\n",
      "Epoch [4/5], Step [201/531], Loss: 0.6665, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6667\n",
      "Epoch [4/5], Step [221/531], Loss: 0.7024, tp_sum: 4.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.5333\n",
      "Epoch [4/5], Step [241/531], Loss: 0.8158, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 5.0000, batch_f1_score: 0.2500\n",
      "Epoch [4/5], Step [261/531], Loss: 0.7204, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 5.0000, batch_f1_score: 0.6316\n",
      "Epoch [4/5], Step [281/531], Loss: 0.7100, tp_sum: 3.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.4000\n",
      "Epoch [4/5], Step [301/531], Loss: 0.6929, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 4.0000, batch_f1_score: 0.4706\n",
      "Epoch [4/5], Step [321/531], Loss: 0.7241, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.6000\n",
      "Epoch [4/5], Step [341/531], Loss: 0.6280, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.4286\n",
      "Epoch [4/5], Step [361/531], Loss: 0.7244, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 6.0000, batch_f1_score: 0.5263\n",
      "Epoch [4/5], Step [381/531], Loss: 0.7730, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 5.0000, batch_f1_score: 0.4444\n",
      "Epoch [4/5], Step [401/531], Loss: 0.6167, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5882\n",
      "Epoch [4/5], Step [421/531], Loss: 0.6263, tp_sum: 6.0000, fp_sum: 0.0000, fn_sum: 5.0000, batch_f1_score: 0.7059\n",
      "Epoch [4/5], Step [441/531], Loss: 0.7856, tp_sum: 3.0000, fp_sum: 6.0000, fn_sum: 3.0000, batch_f1_score: 0.4000\n",
      "Epoch [4/5], Step [461/531], Loss: 0.7436, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 5.0000, batch_f1_score: 0.5556\n",
      "Epoch [4/5], Step [481/531], Loss: 0.8429, tp_sum: 3.0000, fp_sum: 5.0000, fn_sum: 7.0000, batch_f1_score: 0.3333\n",
      "Epoch [4/5], Step [501/531], Loss: 0.6669, tp_sum: 2.0000, fp_sum: 5.0000, fn_sum: 0.0000, batch_f1_score: 0.4444\n",
      "Epoch [4/5], Step [521/531], Loss: 0.6905, tp_sum: 4.0000, fp_sum: 1.0000, fn_sum: 10.0000, batch_f1_score: 0.4211\n",
      "Epoch [5/5], Step [1/531], Loss: 0.7055, tp_sum: 5.0000, fp_sum: 2.0000, fn_sum: 5.0000, batch_f1_score: 0.5882\n",
      "Epoch [5/5], Step [21/531], Loss: 0.6287, tp_sum: 8.0000, fp_sum: 4.0000, fn_sum: 0.0000, batch_f1_score: 0.8000\n",
      "Epoch [5/5], Step [41/531], Loss: 0.6628, tp_sum: 6.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6667\n",
      "Epoch [5/5], Step [61/531], Loss: 0.6123, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 3.0000, batch_f1_score: 0.6250\n",
      "Epoch [5/5], Step [81/531], Loss: 0.6490, tp_sum: 4.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5333\n",
      "Epoch [5/5], Step [101/531], Loss: 0.7039, tp_sum: 4.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.5333\n",
      "Epoch [5/5], Step [121/531], Loss: 0.7476, tp_sum: 4.0000, fp_sum: 6.0000, fn_sum: 3.0000, batch_f1_score: 0.4706\n",
      "Epoch [5/5], Step [141/531], Loss: 0.6215, tp_sum: 8.0000, fp_sum: 2.0000, fn_sum: 2.0000, batch_f1_score: 0.8000\n",
      "Epoch [5/5], Step [161/531], Loss: 0.7276, tp_sum: 4.0000, fp_sum: 5.0000, fn_sum: 1.0000, batch_f1_score: 0.5714\n",
      "Epoch [5/5], Step [181/531], Loss: 0.7101, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 2.0000, batch_f1_score: 0.6250\n",
      "Epoch [5/5], Step [201/531], Loss: 0.8051, tp_sum: 4.0000, fp_sum: 6.0000, fn_sum: 4.0000, batch_f1_score: 0.4444\n",
      "Epoch [5/5], Step [221/531], Loss: 0.6633, tp_sum: 3.0000, fp_sum: 6.0000, fn_sum: 2.0000, batch_f1_score: 0.4286\n",
      "Epoch [5/5], Step [241/531], Loss: 0.6894, tp_sum: 7.0000, fp_sum: 1.0000, fn_sum: 6.0000, batch_f1_score: 0.6667\n",
      "Epoch [5/5], Step [261/531], Loss: 0.7545, tp_sum: 4.0000, fp_sum: 6.0000, fn_sum: 5.0000, batch_f1_score: 0.4211\n",
      "Epoch [5/5], Step [281/531], Loss: 0.7126, tp_sum: 2.0000, fp_sum: 3.0000, fn_sum: 4.0000, batch_f1_score: 0.3636\n",
      "Epoch [5/5], Step [301/531], Loss: 0.6208, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 3.0000, batch_f1_score: 0.7059\n",
      "Epoch [5/5], Step [321/531], Loss: 0.7169, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 4.0000, batch_f1_score: 0.2667\n",
      "Epoch [5/5], Step [341/531], Loss: 0.7870, tp_sum: 2.0000, fp_sum: 5.0000, fn_sum: 7.0000, batch_f1_score: 0.2500\n",
      "Epoch [5/5], Step [361/531], Loss: 0.7516, tp_sum: 5.0000, fp_sum: 3.0000, fn_sum: 7.0000, batch_f1_score: 0.5000\n",
      "Epoch [5/5], Step [381/531], Loss: 0.7444, tp_sum: 6.0000, fp_sum: 1.0000, fn_sum: 6.0000, batch_f1_score: 0.6316\n",
      "Epoch [5/5], Step [401/531], Loss: 0.7534, tp_sum: 3.0000, fp_sum: 4.0000, fn_sum: 4.0000, batch_f1_score: 0.4286\n",
      "Epoch [5/5], Step [421/531], Loss: 0.7148, tp_sum: 3.0000, fp_sum: 6.0000, fn_sum: 3.0000, batch_f1_score: 0.4000\n",
      "Epoch [5/5], Step [441/531], Loss: 0.7358, tp_sum: 3.0000, fp_sum: 5.0000, fn_sum: 5.0000, batch_f1_score: 0.3750\n",
      "Epoch [5/5], Step [461/531], Loss: 0.7608, tp_sum: 5.0000, fp_sum: 4.0000, fn_sum: 3.0000, batch_f1_score: 0.5882\n",
      "Epoch [5/5], Step [481/531], Loss: 0.7007, tp_sum: 4.0000, fp_sum: 2.0000, fn_sum: 5.0000, batch_f1_score: 0.5333\n",
      "Epoch [5/5], Step [501/531], Loss: 0.7495, tp_sum: 2.0000, fp_sum: 7.0000, fn_sum: 2.0000, batch_f1_score: 0.3077\n",
      "Epoch [5/5], Step [521/531], Loss: 0.5619, tp_sum: 6.0000, fp_sum: 2.0000, fn_sum: 0.0000, batch_f1_score: 0.8571\n"
     ]
    }
   ],
   "source": [
    "train(model = model,\n",
    "      train_loader = train_loader,\n",
    "      train_dataset_length = len(train_dataset),\n",
    "      val_loader = val_loader,\n",
    "      num_class = num_class,\n",
    "      device = device,\n",
    "      model_name = \"custom_dnet_binary_by_img_count_lr_1e-3_bs_16_448\",\n",
    "      lr = 1e-3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## function to calculate the F1 score\n",
    "# def f1_score(tp, fp, fn):\n",
    "#     return 2 * (tp) / (2 * tp + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the loss function and optimizer\n",
    "# criterion = nn.BCELoss(reduction='mean')\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n",
    "\n",
    "# # Create a TensorBoard writer\n",
    "# model_name = \"official_dnet_binary_by_img_count_lr_1e-4\"\n",
    "# writer = SummaryWriter(log_dir=f\".//runs//{model_name}_train\")\n",
    "# val_writer = SummaryWriter(log_dir=f\".//runs//{model_name}_val\")\n",
    "\n",
    "# # Train the model\n",
    "# n_epochs = 5\n",
    "# bs = train_loader.batch_size\n",
    "# conf_threshold = 1/num_class\n",
    "# lossMIN = 100000\n",
    "# for epoch in range(n_epochs):\n",
    "\n",
    "#     ## train\n",
    "#     model.train()\n",
    "#     for i, (images, labels) in enumerate(train_loader):\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device).unsqueeze(1).float()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         # Backprop\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         scheduler.step(loss)\n",
    "\n",
    "#         if (i + 1) % 20 == 0:\n",
    "#             # calculate statistics\n",
    "#             tp_array = [0]\n",
    "#             fp_array = [0]\n",
    "#             fn_array = [0]\n",
    "#             pred_labels = (outputs > conf_threshold)\n",
    "#             tp_array += sum(torch.logical_and(pred_labels, labels))\n",
    "#             fp_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), pred_labels))\n",
    "#             fn_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), labels))\n",
    "            \n",
    "#             writer.add_scalar('Loss/img_count', loss, epoch * len(train_dataset) + i * bs)\n",
    "#             writer.add_scalar('TP_Sum/img_count', sum(tp_array), epoch * len(train_dataset) + i * bs)\n",
    "#             writer.add_scalar('FP_Sum/img_count', sum(fp_array), epoch * len(train_dataset) + i * bs)\n",
    "#             writer.add_scalar('FN_Sum/img_count', sum(fn_array), epoch * len(train_dataset) + i * bs)\n",
    "#             writer.add_scalar('F1_Score/img_count', f1_score(sum(tp_array), sum(fp_array), sum(fn_array)), epoch * len(train_dataset) + i * bs)\n",
    "#             print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, tp_sum: {:.4f}, fp_sum: {:.4f}, fn_sum: {:.4f}, batch_f1_score: {:.4f}\".format(epoch + 1, \\\n",
    "#                                                                      n_epochs, \\\n",
    "#                                                                      i + 1, \\\n",
    "#                                                                      len(train_loader), \\\n",
    "#                                                                      loss,\\\n",
    "#                                                                      sum(tp_array), \\\n",
    "#                                                                      sum(fp_array),\\\n",
    "#                                                                      sum(fn_array),\\\n",
    "#                                                                      f1_score(sum(tp_array), sum(fp_array), sum(fn_array))))\n",
    "#         # print(\"outputs\\n\", outputs)\n",
    "#         # print(\"pred_labels\\n\", pred_labels)\n",
    "#         # print(\"actual labels\\n\", labels)\n",
    "\n",
    "#         if loss < lossMIN:\n",
    "#                 lossMIN = loss    \n",
    "#                 torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, r'./dnet_models/m-' + model_name + '.pth.tar')\n",
    "\n",
    "#     ## val\n",
    "#     model.eval()\n",
    "#     ## calculation on the validation side of things\n",
    "#     tp_array = [0]\n",
    "#     fp_array = [0]\n",
    "#     fn_array = [0]\n",
    "\n",
    "#     for i, (images, labels) in enumerate(val_loader):\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device).unsqueeze(1).float()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         pred_labels = (outputs > conf_threshold)\n",
    "#         tp_array += sum(torch.logical_and(pred_labels, labels))\n",
    "#         fp_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), pred_labels))\n",
    "#         fn_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), labels))\n",
    "\n",
    "#     ## write to tensorboard    \n",
    "#     val_writer.add_scalar('Loss/img_count', loss, len(train_dataset) * (epoch+1))\n",
    "#     val_writer.add_scalar('TP_Sum/img_count', sum(tp_array), len(train_dataset) * (epoch+1))\n",
    "#     val_writer.add_scalar('FP_Sum/img_count', sum(fp_array), len(train_dataset) * (epoch+1))\n",
    "#     val_writer.add_scalar('FN_Sum/img_count', sum(fn_array), len(train_dataset) * (epoch+1))\n",
    "#     val_writer.add_scalar('F1_Score/img_count', f1_score(sum(tp_array), sum(fp_array), sum(fn_array)), len(train_dataset) * (epoch+1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
