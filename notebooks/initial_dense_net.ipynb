{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "# device = \"cpu\"\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2037ee347b0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\chexnet', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\notebooks', 'C:\\\\Python312\\\\python312.zip', 'C:\\\\Python312\\\\DLLs', 'C:\\\\Python312\\\\Lib', 'C:\\\\Python312', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv', '', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\siyang\\\\Documents\\\\GitHub\\\\DeepLearningProject\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# run the below line once only\n",
    "if \"..\\\\chexnet\" not in sys.path:\n",
    "    sys.path.insert(0,r'..\\chexnet')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DatasetGenerator import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 2048 images from C:\\Users\\siyang\\Documents\\GitHub\\DeepLearningProject\\chexnet\\dataset\\train_1.txt\n",
      "Collected 2048 images from C:\\Users\\siyang\\Documents\\GitHub\\DeepLearningProject\\chexnet\\dataset\\val_1.txt\n"
     ]
    }
   ],
   "source": [
    "pathDirData = r'C:\\Users\\siyang\\Documents\\GitHub\\DeepLearningProject\\raw_data\\archive'\n",
    "pathFileTrain = r'C:\\Users\\siyang\\Documents\\GitHub\\DeepLearningProject\\chexnet\\dataset\\train_1.txt'\n",
    "pathFileVal = r'C:\\Users\\siyang\\Documents\\GitHub\\DeepLearningProject\\chexnet\\dataset\\val_1.txt'\n",
    "\n",
    "transResize = 256\n",
    "transCrop = 224\n",
    "trBatchSize = 32\n",
    "num_class = 14\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "transformList = []\n",
    "transformList.append(transforms.Resize(transResize))\n",
    "transformList.append(transforms.RandomResizedCrop(transCrop))\n",
    "transformList.append(transforms.RandomHorizontalFlip())\n",
    "transformList.append(transforms.ToTensor())\n",
    "transformList.append(normalize)      \n",
    "transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "datasetTrain = DatasetGenerator(pathImageDirectory=pathDirData, pathDatasetFile=pathFileTrain, transform=transformSequence)\n",
    "datasetVal =   DatasetGenerator(pathImageDirectory=pathDirData, pathDatasetFile=pathFileVal, transform=transformSequence)\n",
    "train_loader = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=12, pin_memory=True)\n",
    "val_loader = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=12, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dense_layer(nn.Module):\n",
    "    def __init__(self, dim, training):\n",
    "        super(dense_layer, self).__init__()\n",
    "        eps = 1e-5\n",
    "        momentum = 0.1\n",
    "        hidden_dim = 128\n",
    "        output_dim = 32\n",
    "        self.training = training\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=dim, eps=eps, momentum=momentum, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=dim, out_channels=hidden_dim, kernel_size=(1,1), stride=(1,1),bias=False),\n",
    "            nn.BatchNorm2d(num_features=hidden_dim, eps=eps, momentum=momentum, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=hidden_dim, out_channels=output_dim, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dropout_rate = 0\n",
    "        return F.dropout(self.net(x), p = dropout_rate, training=self.training)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class _DenseLayer(nn.Module):\n",
    "#     def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n",
    "#         super(_DenseLayer, self).__init__()\n",
    "#         self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "#         self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "#         self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "#                                            growth_rate, kernel_size=1, stride=1,\n",
    "#                                            bias=False)),\n",
    "#         self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "#         self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "#         self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "#                                            kernel_size=3, stride=1, padding=1,\n",
    "#                                            bias=False)),\n",
    "#         self.drop_rate = float(drop_rate)\n",
    "#         self.memory_efficient = memory_efficient\n",
    "\n",
    "#     def bn_function(self, inputs):\n",
    "#         \"Bottleneck function\"\n",
    "#         # type: (List[Tensor]) -> Tensor\n",
    "#         concated_features = torch.cat(inputs, 1)\n",
    "#         bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\n",
    "#         return bottleneck_output\n",
    "\n",
    "#     def forward(self, input):  # noqa: F811\n",
    "#         if isinstance(input, torch.Tensor):\n",
    "#             prev_features = [input]\n",
    "#         else:\n",
    "#             prev_features = input\n",
    "\n",
    "#         bottleneck_output = self.bn_function(prev_features)\n",
    "#         new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
    "#         if self.drop_rate > 0:\n",
    "#             new_features = F.dropout(new_features, p=self.drop_rate,\n",
    "#                                      training=self.training)\n",
    "#         return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dense_layer(nn.Module):\n",
    "#     def __init__(self, dim, training):\n",
    "#         super(dense_layer, self).__init__()\n",
    "#         eps = 1e-5\n",
    "#         momentum = 0.1\n",
    "#         hidden_dim = 128\n",
    "#         output_dim = 32\n",
    "#         self.training = training\n",
    "#         # self.net = nn.Sequential(\n",
    "#         self.norm1 = nn.BatchNorm2d(num_features=dim, eps=eps, momentum=momentum, affine=True, track_running_stats=True)\n",
    "#         self.relu1 = nn.ReLU(inplace=True)\n",
    "#         self.conv1 = nn.Conv2d(in_channels=dim, out_channels=hidden_dim, kernel_size=(1,1), stride=(1,1),bias=False)\n",
    "#         self.norm2 = nn.BatchNorm2d(num_features=hidden_dim, eps=eps, momentum=momentum, affine=True, track_running_stats=True)\n",
    "#         self.relu2 = nn.ReLU(inplace=True)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=hidden_dim, out_channels=output_dim, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)\n",
    "#         # )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         dropout_rate = 0\n",
    "#         x = self.norm1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.norm2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         x = self.conv2(x)\n",
    "#         return F.dropout(x, p = dropout_rate, training=self.training)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseLayer(nn.Module):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                                           growth_rate, kernel_size=1, stride=1,\n",
    "                                           bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                                           kernel_size=3, stride=1, padding=1,\n",
    "                                           bias=False)),\n",
    "        self.drop_rate = float(drop_rate)\n",
    "        self.memory_efficient = memory_efficient\n",
    "\n",
    "    def bn_function(self, inputs):\n",
    "        \"Bottleneck function\"\n",
    "        # type: (List[Tensor]) -> Tensor\n",
    "        concated_features = torch.cat(inputs, 1)\n",
    "        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\n",
    "        return bottleneck_output\n",
    "\n",
    "    def forward(self, input):  # noqa: F811\n",
    "        if isinstance(input, torch.Tensor):\n",
    "            prev_features = [input]\n",
    "        else:\n",
    "            prev_features = input\n",
    "\n",
    "        bottleneck_output = self.bn_function(prev_features)\n",
    "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
    "                                     training=self.training)\n",
    "        return new_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dense_block(nn.ModuleDict):\n",
    "    def __init__(self, layer_count, dim, training):\n",
    "        super(dense_block, self).__init__()\n",
    "        hidden_dim = dim\n",
    "        growth_rate = 32\n",
    "        for layer_index in range(layer_count):\n",
    "            # setattr(self, f'layer_{layer_index}',dense_layer(hidden_dim, training=training))\n",
    "            # ## update the hidden_dim so that the input size of the next layer has space\n",
    "            # ## for all the outputs that precede it\n",
    "            # hidden_dim += getattr(self,f'layer_{layer_index}').net[5].out_channels\n",
    "            layer = dense_layer(\n",
    "                dim = hidden_dim,\n",
    "                training=training\n",
    "            )\n",
    "            self.add_module(f\"dense_layer{layer_index}\", layer)\n",
    "            hidden_dim += growth_rate\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        for _, layer in self.items():\n",
    "            # print(\"working in \" + str(layer._get_name()) + \" ...\")\n",
    "            new_output = layer(output)\n",
    "            # print(\"output of this dense_layer is \" + str(new_output.shape))\n",
    "            ## add the new_output to the previous output\n",
    "            ## for the next layer in the block\n",
    "            # print(\"output shape\", str(output.shape))\n",
    "            # print(\"new_output shape\", str(new_output.shape))\n",
    "            output = torch.cat((output,new_output),1) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dense_block(nn.ModuleDict):\n",
    "#     def __init__(self, layer_count, dim, training):\n",
    "#         super(dense_block, self).__init__()\n",
    "#         hidden_dim = dim\n",
    "#         growth_rate = 32\n",
    "#         for layer_index in range(layer_count):\n",
    "#             # setattr(self, f'layer_{layer_index}',dense_layer(hidden_dim, training=training))\n",
    "#             # ## update the hidden_dim so that the input size of the next layer has space\n",
    "#             # ## for all the outputs that precede it\n",
    "#             # hidden_dim += getattr(self,f'layer_{layer_index}').net[5].out_channels\n",
    "#             layer = _DenseLayer(\n",
    "#                 num_input_features = dim + layer_index * growth_rate,\n",
    "#                 growth_rate=growth_rate,\n",
    "#                 bn_size=4,\n",
    "#                 drop_rate=0,\n",
    "#                 memory_efficient=False,\n",
    "#             )\n",
    "#             self.add_module(f\"dense_layer{layer_index}\", layer)\n",
    "#             hidden_dim += growth_rate\n",
    "\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         output = input\n",
    "#         for _, layer in self.items():\n",
    "#             # print(\"working in \" + str(layer._get_name()) + \" ...\")\n",
    "#             new_output = layer(output)\n",
    "#             # print(\"output of this dense_layer is \" + str(new_output.shape))\n",
    "#             ## add the new_output to the previous output\n",
    "#             ## for the next layer in the block\n",
    "#             # print(\"output shape\", str(output.shape))\n",
    "#             # print(\"new_output shape\", str(new_output.shape))\n",
    "#             output = torch.cat((output,new_output),1) \n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transition_block(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(transition_block, self).__init__()\n",
    "        eps = 1e-5\n",
    "        momentum = 0.1\n",
    "        self.norm = nn.BatchNorm2d(channels, eps=eps, momentum=momentum, affine=True, track_running_stats=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(channels, channels//2, kernel_size=(1,1), stride=(1,1), bias=False)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2,stride=2,padding=0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        for layer in self.children():\n",
    "            # print(\"working in \" + str(layer._get_name()) + \" ...\")\n",
    "            x = layer(x)\n",
    "            # print(\"output of this transition is \" + str(x.shape))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dense_net(nn.Module):\n",
    "    def __init__(self, num_class, training):\n",
    "        super(dense_net, self).__init__()\n",
    "        hidden_dim = 64\n",
    "\n",
    "        self.initial_setup = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=hidden_dim, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False),\n",
    "            nn.BatchNorm2d(num_features=hidden_dim, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride = 2,padding=1, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "\n",
    "        ## just calculate the number of channels in trans blocks manually\n",
    "        ## since we know initial channel number and how many layers are in each block\n",
    "        self.denseblock1 = dense_block(layer_count=6, dim=hidden_dim, training=training)\n",
    "        self.trans1 = transition_block(channels = hidden_dim + 6 * 32) # 256 \n",
    "        self.denseblock2 = dense_block(layer_count=12, dim=hidden_dim * 2, training=training)\n",
    "        self.trans2 = transition_block(channels = hidden_dim * 2 + 12 * 32) #512\n",
    "        self.denseblock3 = dense_block(layer_count=24, dim=hidden_dim * 4, training=training)\n",
    "        self.trans3 = transition_block(channels = hidden_dim * 4 + 24 * 32) # 1024\n",
    "        self.denseblock4 = dense_block(layer_count=16, dim=hidden_dim * 8, training=training)\n",
    "        self.norm5 = nn.BatchNorm2d(num_features=hidden_dim * 8 + 16 * 32)\n",
    "\n",
    "        ## preparing input into the classifier\n",
    "        self.adaptive_avg_pool = nn.AdaptiveAvgPool2d((1,1)) ## global average pooling\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        ## classifier component:\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=self.norm5.num_features, out_features=num_class, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        ## initialize to random values\n",
    "        kaiming = norm = linear = False\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                kaiming = True\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                norm = True\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                linear = True\n",
    "\n",
    "        print(kaiming,norm,linear)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        for block in self.children():\n",
    "            # print(\"working in \" + str(block._get_name()) + \" ...\")\n",
    "            x = block(x)\n",
    "            # print(\"output of this block is \" + str(x.shape))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dense_net(\n",
       "  (initial_setup): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (denseblock1): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans1): transition_block(\n",
       "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock2): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer6): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer7): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer8): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer9): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer10): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer11): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans2): transition_block(\n",
       "    (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock3): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer6): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer7): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer8): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer9): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer10): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer11): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer12): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer13): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer14): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer15): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer16): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer17): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer18): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer19): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer20): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer21): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer22): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer23): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trans3): transition_block(\n",
       "    (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (denseblock4): dense_block(\n",
       "    (dense_layer0): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer1): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer2): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer3): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer4): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer5): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer6): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer7): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer8): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer9): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer10): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer11): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer12): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer13): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer14): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (dense_layer15): dense_layer(\n",
       "      (net): Sequential(\n",
       "        (0): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (adaptive_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=14, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = dense_net(14, training = True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.2272, -0.0758, -0.0426,  ...,  0.0247, -0.0265,  0.0591],\n",
       "          [-0.1045, -0.0152,  0.3049,  ...,  0.0035,  0.1152, -0.1008],\n",
       "          [-0.0401, -0.0739, -0.0767,  ..., -0.0596, -0.1044, -0.1815],\n",
       "          ...,\n",
       "          [ 0.2348, -0.0762, -0.0697,  ...,  0.0192,  0.1652,  0.0346],\n",
       "          [ 0.1162, -0.0160, -0.0116,  ..., -0.2688,  0.3540,  0.0842],\n",
       "          [-0.0030, -0.0638,  0.0365,  ..., -0.0308,  0.1739, -0.0121]],\n",
       "\n",
       "         [[-0.0104, -0.1915, -0.1581,  ..., -0.0985, -0.0422,  0.0477],\n",
       "          [ 0.1287,  0.0841,  0.0459,  ..., -0.0032,  0.1101, -0.0705],\n",
       "          [ 0.0070,  0.1659, -0.0404,  ..., -0.0164, -0.0870,  0.0342],\n",
       "          ...,\n",
       "          [-0.0533, -0.1078,  0.0498,  ..., -0.0314,  0.0680, -0.2729],\n",
       "          [ 0.0389, -0.0120, -0.0760,  ..., -0.0830,  0.1380,  0.0346],\n",
       "          [-0.2495, -0.1623, -0.0374,  ...,  0.2057, -0.0067,  0.0479]],\n",
       "\n",
       "         [[-0.0412, -0.1994, -0.0258,  ...,  0.1540,  0.0191, -0.0733],\n",
       "          [-0.0161,  0.0687, -0.0845,  ..., -0.0192,  0.1162,  0.0208],\n",
       "          [-0.0445,  0.1457,  0.0248,  ..., -0.0748, -0.0120, -0.0698],\n",
       "          ...,\n",
       "          [ 0.0753, -0.0506, -0.0737,  ...,  0.0667, -0.0130, -0.1574],\n",
       "          [-0.0107, -0.0862,  0.1234,  ...,  0.0115, -0.0994, -0.0321],\n",
       "          [ 0.0337, -0.0249,  0.1074,  ...,  0.1547,  0.1434,  0.0006]]],\n",
       "\n",
       "\n",
       "        [[[-0.0248, -0.1540,  0.0245,  ...,  0.1311, -0.0668,  0.0578],\n",
       "          [ 0.0158, -0.0869, -0.0531,  ..., -0.1315,  0.0497,  0.1275],\n",
       "          [-0.0148, -0.0695, -0.0840,  ..., -0.1219,  0.0569, -0.0389],\n",
       "          ...,\n",
       "          [-0.2351,  0.0512,  0.1526,  ..., -0.0257, -0.0862,  0.0553],\n",
       "          [ 0.0499,  0.1023, -0.0662,  ..., -0.2147, -0.0768, -0.1374],\n",
       "          [-0.1263,  0.0739, -0.0472,  ..., -0.0718,  0.0703,  0.1479]],\n",
       "\n",
       "         [[-0.0340, -0.0842,  0.0016,  ...,  0.1096,  0.1273,  0.2239],\n",
       "          [ 0.0164,  0.0183, -0.1521,  ..., -0.0250, -0.0808, -0.0432],\n",
       "          [ 0.0129,  0.1173,  0.1248,  ...,  0.1259, -0.2530, -0.2093],\n",
       "          ...,\n",
       "          [-0.1408,  0.0868, -0.1192,  ...,  0.0556, -0.0627,  0.0842],\n",
       "          [ 0.0329, -0.0862,  0.0740,  ..., -0.0675,  0.1815,  0.0025],\n",
       "          [ 0.0997, -0.0977, -0.0811,  ...,  0.0867,  0.2392, -0.1636]],\n",
       "\n",
       "         [[-0.2244,  0.0947,  0.0053,  ..., -0.1595, -0.0276,  0.0095],\n",
       "          [-0.0025, -0.0392,  0.1534,  ..., -0.0030, -0.2260,  0.1651],\n",
       "          [-0.0553, -0.1158,  0.2060,  ..., -0.0785,  0.0403,  0.1242],\n",
       "          ...,\n",
       "          [-0.0759, -0.2607,  0.0781,  ...,  0.0310,  0.0953, -0.0397],\n",
       "          [-0.0095,  0.1167,  0.0557,  ..., -0.1284, -0.1094,  0.0558],\n",
       "          [ 0.0212, -0.0326,  0.0026,  ...,  0.1769, -0.0706,  0.2993]]],\n",
       "\n",
       "\n",
       "        [[[-0.0158,  0.0685, -0.0318,  ..., -0.0662,  0.1490,  0.1688],\n",
       "          [-0.1627,  0.1418,  0.0752,  ..., -0.0075, -0.1197,  0.0967],\n",
       "          [-0.0036,  0.0818,  0.0349,  ..., -0.1548, -0.2598,  0.0592],\n",
       "          ...,\n",
       "          [ 0.1269,  0.2946, -0.1739,  ..., -0.0756,  0.0184,  0.0350],\n",
       "          [ 0.0450, -0.0219,  0.1434,  ...,  0.0141, -0.1270, -0.1351],\n",
       "          [ 0.0143, -0.1449, -0.0659,  ...,  0.0208, -0.0032,  0.0867]],\n",
       "\n",
       "         [[ 0.2355,  0.1809, -0.3046,  ...,  0.0221,  0.2043, -0.2253],\n",
       "          [-0.2084, -0.0656,  0.1052,  ..., -0.1466,  0.0976, -0.0934],\n",
       "          [-0.1124,  0.0526, -0.1083,  ...,  0.0004, -0.1477,  0.0919],\n",
       "          ...,\n",
       "          [ 0.0070, -0.0991,  0.2120,  ..., -0.0415, -0.0886, -0.1097],\n",
       "          [ 0.1533, -0.0677,  0.0634,  ...,  0.0070, -0.0971, -0.1224],\n",
       "          [ 0.1305, -0.0119, -0.1336,  ..., -0.1084, -0.0092, -0.0187]],\n",
       "\n",
       "         [[-0.0501, -0.2787, -0.1684,  ..., -0.1177, -0.0795,  0.2688],\n",
       "          [ 0.0270, -0.0272,  0.0346,  ...,  0.0486,  0.0321, -0.2377],\n",
       "          [-0.0048, -0.1755,  0.1681,  ...,  0.0705, -0.0663,  0.1125],\n",
       "          ...,\n",
       "          [ 0.0329, -0.0205, -0.1039,  ...,  0.1448,  0.1299,  0.1476],\n",
       "          [-0.1028,  0.1443,  0.1478,  ..., -0.0124, -0.0568, -0.0519],\n",
       "          [ 0.2233, -0.1132, -0.0676,  ..., -0.0037,  0.0449, -0.2611]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0018, -0.0016,  0.0890,  ...,  0.1167,  0.1060, -0.1648],\n",
       "          [-0.0642, -0.0628, -0.1739,  ...,  0.0570, -0.0209,  0.1799],\n",
       "          [-0.0281,  0.0353, -0.1036,  ..., -0.2005, -0.2486, -0.0074],\n",
       "          ...,\n",
       "          [ 0.0672,  0.0906, -0.2287,  ...,  0.0651, -0.0203,  0.0356],\n",
       "          [ 0.0319,  0.0593, -0.2323,  ..., -0.0654,  0.0642, -0.0294],\n",
       "          [ 0.2274,  0.2302,  0.1216,  ..., -0.0820, -0.1075, -0.1715]],\n",
       "\n",
       "         [[-0.0173,  0.0321, -0.0644,  ..., -0.1619, -0.1874, -0.2826],\n",
       "          [ 0.1048, -0.1341, -0.1109,  ...,  0.0563, -0.0962,  0.2287],\n",
       "          [ 0.2374, -0.1026,  0.0202,  ...,  0.0175, -0.0776, -0.2329],\n",
       "          ...,\n",
       "          [ 0.0579, -0.0889, -0.1207,  ..., -0.0523,  0.1513, -0.1951],\n",
       "          [-0.2116,  0.1532, -0.0961,  ...,  0.0574,  0.1305, -0.0377],\n",
       "          [ 0.0212,  0.2195, -0.0195,  ..., -0.1125,  0.1157, -0.0870]],\n",
       "\n",
       "         [[ 0.0016,  0.0327,  0.1368,  ...,  0.0099,  0.0858,  0.1498],\n",
       "          [ 0.2192,  0.0243,  0.1428,  ..., -0.0247, -0.0289,  0.0918],\n",
       "          [-0.0041,  0.0489, -0.0457,  ..., -0.0995, -0.1856, -0.0232],\n",
       "          ...,\n",
       "          [-0.0858,  0.0737, -0.0296,  ...,  0.0649, -0.0728, -0.0763],\n",
       "          [-0.1063, -0.0909, -0.0957,  ...,  0.0818, -0.0028,  0.0859],\n",
       "          [-0.0359, -0.2464, -0.0787,  ...,  0.0775, -0.0034,  0.2001]]],\n",
       "\n",
       "\n",
       "        [[[-0.0751, -0.0615,  0.1568,  ..., -0.0542, -0.1455, -0.0301],\n",
       "          [-0.2010, -0.0383, -0.1353,  ..., -0.1277, -0.1855,  0.1035],\n",
       "          [-0.1069,  0.0985, -0.0310,  ..., -0.1908,  0.0089, -0.0603],\n",
       "          ...,\n",
       "          [ 0.0116, -0.0184, -0.0500,  ..., -0.0309, -0.0041,  0.1608],\n",
       "          [-0.1338,  0.0744, -0.0249,  ...,  0.0505, -0.0657,  0.0580],\n",
       "          [-0.1366, -0.0404, -0.0320,  ...,  0.0364, -0.0879,  0.0442]],\n",
       "\n",
       "         [[-0.1900, -0.0728, -0.1241,  ...,  0.0483, -0.1163,  0.1235],\n",
       "          [ 0.1369,  0.1310, -0.0526,  ...,  0.0551, -0.0994, -0.1269],\n",
       "          [-0.0004, -0.1260,  0.1484,  ...,  0.0386,  0.0046,  0.1575],\n",
       "          ...,\n",
       "          [-0.0416, -0.0695, -0.0426,  ...,  0.0868,  0.0078,  0.2652],\n",
       "          [-0.0394, -0.0138, -0.0055,  ...,  0.1136, -0.3084, -0.2184],\n",
       "          [-0.1388,  0.2436,  0.2088,  ...,  0.1165,  0.0881,  0.1768]],\n",
       "\n",
       "         [[ 0.1172, -0.0124,  0.0085,  ...,  0.1661, -0.0589,  0.0674],\n",
       "          [-0.2607,  0.2286,  0.0542,  ..., -0.0899, -0.1782,  0.2498],\n",
       "          [ 0.0625, -0.1136,  0.0424,  ..., -0.0570, -0.0403, -0.0837],\n",
       "          ...,\n",
       "          [ 0.0356,  0.1127, -0.1217,  ...,  0.0644,  0.2146, -0.0225],\n",
       "          [ 0.0415, -0.0786, -0.0488,  ...,  0.1409,  0.0457,  0.1407],\n",
       "          [ 0.0363,  0.1544,  0.0358,  ...,  0.0027, -0.0813, -0.1209]]],\n",
       "\n",
       "\n",
       "        [[[-0.0785,  0.0046, -0.0283,  ..., -0.0268,  0.2432, -0.2333],\n",
       "          [ 0.0314,  0.0508, -0.1633,  ...,  0.1465,  0.0295, -0.0294],\n",
       "          [ 0.0097, -0.0729, -0.0067,  ...,  0.0204,  0.0180,  0.2120],\n",
       "          ...,\n",
       "          [-0.1280,  0.1019,  0.1359,  ...,  0.2093, -0.1229,  0.1184],\n",
       "          [ 0.0924,  0.0395, -0.1406,  ...,  0.0731,  0.1754, -0.1754],\n",
       "          [ 0.0029,  0.0505,  0.1980,  ...,  0.0825,  0.0463, -0.0830]],\n",
       "\n",
       "         [[ 0.0536,  0.0627,  0.0402,  ..., -0.1046, -0.0323,  0.2398],\n",
       "          [ 0.1295,  0.0939,  0.0081,  ..., -0.1450,  0.2264, -0.0489],\n",
       "          [ 0.1562,  0.0115,  0.0725,  ...,  0.0038,  0.1984, -0.0620],\n",
       "          ...,\n",
       "          [-0.0143,  0.1709, -0.1151,  ...,  0.2182,  0.0281,  0.1829],\n",
       "          [-0.0475,  0.0342,  0.0209,  ...,  0.0687, -0.1504,  0.0823],\n",
       "          [ 0.0685, -0.0415,  0.0974,  ...,  0.0391, -0.0416,  0.2325]],\n",
       "\n",
       "         [[-0.1469, -0.1015, -0.0414,  ...,  0.1523,  0.0227, -0.1105],\n",
       "          [-0.0647, -0.0829,  0.0593,  ...,  0.0141, -0.0866, -0.0041],\n",
       "          [-0.1148, -0.1198,  0.0336,  ..., -0.0534,  0.0639, -0.2426],\n",
       "          ...,\n",
       "          [-0.0020, -0.0140,  0.2132,  ..., -0.1224, -0.2830,  0.1440],\n",
       "          [ 0.1219,  0.0978,  0.1332,  ...,  0.0764, -0.0034, -0.1949],\n",
       "          [ 0.0140,  0.0590,  0.0633,  ...,  0.1282, -0.0390,  0.0608]]]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.initial_setup[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to calculate the F1 score\n",
    "def f1_score(tp, fp, fn):\n",
    "    return 2 * (tp) / (2 * tp + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [1/64], Loss: 0.6967, tp_sum: 25.0000, fp_sum: 423.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1057\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [2/64], Loss: 0.7703, tp_sum: 23.0000, fp_sum: 424.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0979\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [3/64], Loss: 0.7116, tp_sum: 24.0000, fp_sum: 423.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1019\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [4/64], Loss: 0.7082, tp_sum: 25.0000, fp_sum: 423.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1057\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [5/64], Loss: 0.7103, tp_sum: 24.0000, fp_sum: 424.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1017\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [6/64], Loss: 0.6999, tp_sum: 20.0000, fp_sum: 428.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0855\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [7/64], Loss: 0.6846, tp_sum: 29.0000, fp_sum: 419.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1216\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [8/64], Loss: 0.6876, tp_sum: 22.0000, fp_sum: 426.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0936\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [9/64], Loss: 0.6821, tp_sum: 29.0000, fp_sum: 419.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1216\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [10/64], Loss: 0.6936, tp_sum: 18.0000, fp_sum: 430.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0773\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [11/64], Loss: 0.6846, tp_sum: 26.0000, fp_sum: 422.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1097\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [12/64], Loss: 0.6818, tp_sum: 13.0000, fp_sum: 435.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0564\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [13/64], Loss: 0.6703, tp_sum: 26.0000, fp_sum: 422.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1097\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [14/64], Loss: 0.6705, tp_sum: 8.0000, fp_sum: 440.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0351\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [15/64], Loss: 0.6617, tp_sum: 24.0000, fp_sum: 424.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1017\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [16/64], Loss: 0.6582, tp_sum: 16.0000, fp_sum: 432.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0690\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [17/64], Loss: 0.6541, tp_sum: 19.0000, fp_sum: 429.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0814\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [18/64], Loss: 0.6446, tp_sum: 14.0000, fp_sum: 434.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0606\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [19/64], Loss: 0.6393, tp_sum: 26.0000, fp_sum: 422.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1097\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [20/64], Loss: 0.6466, tp_sum: 23.0000, fp_sum: 425.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0977\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [21/64], Loss: 0.6306, tp_sum: 28.0000, fp_sum: 420.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1176\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [22/64], Loss: 0.6344, tp_sum: 26.0000, fp_sum: 422.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1097\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [23/64], Loss: 0.6172, tp_sum: 14.0000, fp_sum: 434.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0606\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [24/64], Loss: 0.6137, tp_sum: 19.0000, fp_sum: 429.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0814\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [25/64], Loss: 0.6023, tp_sum: 13.0000, fp_sum: 435.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0564\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [26/64], Loss: 0.6032, tp_sum: 23.0000, fp_sum: 425.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0977\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [27/64], Loss: 0.5930, tp_sum: 16.0000, fp_sum: 431.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0691\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [28/64], Loss: 0.5817, tp_sum: 17.0000, fp_sum: 430.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0733\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [29/64], Loss: 0.5750, tp_sum: 18.0000, fp_sum: 430.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0773\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [30/64], Loss: 0.5597, tp_sum: 17.0000, fp_sum: 431.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0731\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [31/64], Loss: 0.5551, tp_sum: 25.0000, fp_sum: 423.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1057\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [32/64], Loss: 0.5476, tp_sum: 27.0000, fp_sum: 421.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1137\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [33/64], Loss: 0.5442, tp_sum: 28.0000, fp_sum: 420.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1176\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [34/64], Loss: 0.5227, tp_sum: 21.0000, fp_sum: 427.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0896\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [35/64], Loss: 0.5108, tp_sum: 11.0000, fp_sum: 437.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0479\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [36/64], Loss: 0.5006, tp_sum: 27.0000, fp_sum: 421.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1137\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [37/64], Loss: 0.4976, tp_sum: 28.0000, fp_sum: 420.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1176\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [38/64], Loss: 0.4793, tp_sum: 22.0000, fp_sum: 426.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0936\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [39/64], Loss: 0.4731, tp_sum: 17.0000, fp_sum: 430.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0733\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [40/64], Loss: 0.4567, tp_sum: 22.0000, fp_sum: 426.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0936\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [41/64], Loss: 0.4411, tp_sum: 22.0000, fp_sum: 426.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0936\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [42/64], Loss: 0.4419, tp_sum: 27.0000, fp_sum: 419.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1142\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [43/64], Loss: 0.4175, tp_sum: 21.0000, fp_sum: 427.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0896\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [44/64], Loss: 0.4049, tp_sum: 18.0000, fp_sum: 430.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0773\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [45/64], Loss: 0.3935, tp_sum: 21.0000, fp_sum: 427.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0896\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [46/64], Loss: 0.3864, tp_sum: 22.0000, fp_sum: 425.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0938\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [47/64], Loss: 0.3669, tp_sum: 16.0000, fp_sum: 432.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0690\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [48/64], Loss: 0.3563, tp_sum: 22.0000, fp_sum: 426.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0936\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [49/64], Loss: 0.3393, tp_sum: 17.0000, fp_sum: 431.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0731\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [50/64], Loss: 0.3377, tp_sum: 22.0000, fp_sum: 426.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0936\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [51/64], Loss: 0.3279, tp_sum: 20.0000, fp_sum: 426.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0858\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [52/64], Loss: 0.3125, tp_sum: 17.0000, fp_sum: 426.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0739\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [53/64], Loss: 0.3029, tp_sum: 15.0000, fp_sum: 425.0000, fn_sum: 1.0000, cumulative_f1_score: 0.0658\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [54/64], Loss: 0.2910, tp_sum: 21.0000, fp_sum: 427.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0896\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [55/64], Loss: 0.3008, tp_sum: 23.0000, fp_sum: 424.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0979\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [56/64], Loss: 0.2712, tp_sum: 17.0000, fp_sum: 431.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0731\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [57/64], Loss: 0.2859, tp_sum: 27.0000, fp_sum: 421.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1137\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [58/64], Loss: 0.2743, tp_sum: 25.0000, fp_sum: 415.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1075\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [59/64], Loss: 0.2596, tp_sum: 23.0000, fp_sum: 397.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1038\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [60/64], Loss: 0.2474, tp_sum: 21.0000, fp_sum: 405.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0940\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [61/64], Loss: 0.2384, tp_sum: 14.0000, fp_sum: 396.0000, fn_sum: 3.0000, cumulative_f1_score: 0.0656\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [62/64], Loss: 0.2334, tp_sum: 21.0000, fp_sum: 383.0000, fn_sum: 0.0000, cumulative_f1_score: 0.0988\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [63/64], Loss: 0.2492, tp_sum: 26.0000, fp_sum: 368.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1238\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [1/5], Step [64/64], Loss: 0.2306, tp_sum: 21.0000, fp_sum: 373.0000, fn_sum: 1.0000, cumulative_f1_score: 0.1010\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [1/64], Loss: 0.2500, tp_sum: 30.0000, fp_sum: 353.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1453\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [2/64], Loss: 0.2196, tp_sum: 23.0000, fp_sum: 340.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1192\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [3/64], Loss: 0.2367, tp_sum: 25.0000, fp_sum: 323.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1333\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [4/64], Loss: 0.2184, tp_sum: 23.0000, fp_sum: 314.0000, fn_sum: 0.0000, cumulative_f1_score: 0.1278\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [5/64], Loss: 0.2272, tp_sum: 25.0000, fp_sum: 302.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1412\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [6/64], Loss: 0.2051, tp_sum: 19.0000, fp_sum: 283.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1176\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [7/64], Loss: 0.2034, tp_sum: 14.0000, fp_sum: 271.0000, fn_sum: 5.0000, cumulative_f1_score: 0.0921\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [8/64], Loss: 0.1968, tp_sum: 18.0000, fp_sum: 266.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1180\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [9/64], Loss: 0.1932, tp_sum: 18.0000, fp_sum: 257.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1216\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [10/64], Loss: 0.1715, tp_sum: 13.0000, fp_sum: 252.0000, fn_sum: 3.0000, cumulative_f1_score: 0.0925\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [11/64], Loss: 0.2059, tp_sum: 23.0000, fp_sum: 231.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1643\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [12/64], Loss: 0.2151, tp_sum: 17.0000, fp_sum: 228.0000, fn_sum: 10.0000, cumulative_f1_score: 0.1250\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [13/64], Loss: 0.2171, tp_sum: 20.0000, fp_sum: 194.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1667\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [14/64], Loss: 0.1880, tp_sum: 13.0000, fp_sum: 182.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1215\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [15/64], Loss: 0.1822, tp_sum: 20.0000, fp_sum: 179.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1810\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [16/64], Loss: 0.1895, tp_sum: 20.0000, fp_sum: 189.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1717\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [17/64], Loss: 0.1809, tp_sum: 15.0000, fp_sum: 185.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1357\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [18/64], Loss: 0.1894, tp_sum: 19.0000, fp_sum: 183.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1681\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [19/64], Loss: 0.2345, tp_sum: 21.0000, fp_sum: 194.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1721\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [20/64], Loss: 0.1162, tp_sum: 5.0000, fp_sum: 202.0000, fn_sum: 2.0000, cumulative_f1_score: 0.0467\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [21/64], Loss: 0.2426, tp_sum: 23.0000, fp_sum: 182.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1949\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [22/64], Loss: 0.1864, tp_sum: 19.0000, fp_sum: 191.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1631\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [23/64], Loss: 0.1758, tp_sum: 23.0000, fp_sum: 173.0000, fn_sum: 0.0000, cumulative_f1_score: 0.2100\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [24/64], Loss: 0.2321, tp_sum: 27.0000, fp_sum: 173.0000, fn_sum: 6.0000, cumulative_f1_score: 0.2318\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [25/64], Loss: 0.1750, tp_sum: 14.0000, fp_sum: 173.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1353\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [26/64], Loss: 0.1506, tp_sum: 15.0000, fp_sum: 179.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1422\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [27/64], Loss: 0.1989, tp_sum: 21.0000, fp_sum: 166.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1972\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [28/64], Loss: 0.1860, tp_sum: 13.0000, fp_sum: 173.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1262\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [29/64], Loss: 0.2001, tp_sum: 21.0000, fp_sum: 164.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1991\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [30/64], Loss: 0.1771, tp_sum: 18.0000, fp_sum: 172.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1698\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [31/64], Loss: 0.1804, tp_sum: 17.0000, fp_sum: 175.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1589\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [32/64], Loss: 0.1778, tp_sum: 18.0000, fp_sum: 165.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1756\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [33/64], Loss: 0.1960, tp_sum: 12.0000, fp_sum: 188.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1091\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [34/64], Loss: 0.1974, tp_sum: 13.0000, fp_sum: 175.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1238\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [35/64], Loss: 0.1562, tp_sum: 11.0000, fp_sum: 173.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1100\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [36/64], Loss: 0.1712, tp_sum: 12.0000, fp_sum: 167.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1212\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [37/64], Loss: 0.1931, tp_sum: 14.0000, fp_sum: 183.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1279\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [38/64], Loss: 0.1539, tp_sum: 14.0000, fp_sum: 179.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1340\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [39/64], Loss: 0.1572, tp_sum: 12.0000, fp_sum: 165.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1244\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [40/64], Loss: 0.1534, tp_sum: 8.0000, fp_sum: 174.0000, fn_sum: 6.0000, cumulative_f1_score: 0.0816\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [41/64], Loss: 0.1636, tp_sum: 16.0000, fp_sum: 168.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1569\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [42/64], Loss: 0.2011, tp_sum: 19.0000, fp_sum: 165.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1818\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [43/64], Loss: 0.1627, tp_sum: 8.0000, fp_sum: 180.0000, fn_sum: 7.0000, cumulative_f1_score: 0.0788\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [44/64], Loss: 0.1419, tp_sum: 8.0000, fp_sum: 184.0000, fn_sum: 5.0000, cumulative_f1_score: 0.0780\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [45/64], Loss: 0.1918, tp_sum: 15.0000, fp_sum: 170.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1463\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [46/64], Loss: 0.2053, tp_sum: 17.0000, fp_sum: 173.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1581\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [47/64], Loss: 0.1598, tp_sum: 14.0000, fp_sum: 175.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1353\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [48/64], Loss: 0.1827, tp_sum: 19.0000, fp_sum: 176.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1743\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [49/64], Loss: 0.1688, tp_sum: 15.0000, fp_sum: 178.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1408\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [50/64], Loss: 0.1879, tp_sum: 12.0000, fp_sum: 176.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1154\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [51/64], Loss: 0.1532, tp_sum: 15.0000, fp_sum: 167.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1508\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [52/64], Loss: 0.1700, tp_sum: 15.0000, fp_sum: 176.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1429\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [53/64], Loss: 0.1310, tp_sum: 7.0000, fp_sum: 176.0000, fn_sum: 4.0000, cumulative_f1_score: 0.0722\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [54/64], Loss: 0.1556, tp_sum: 13.0000, fp_sum: 180.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1244\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [55/64], Loss: 0.1641, tp_sum: 11.0000, fp_sum: 180.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1058\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [56/64], Loss: 0.1755, tp_sum: 13.0000, fp_sum: 170.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1287\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [57/64], Loss: 0.1697, tp_sum: 10.0000, fp_sum: 187.0000, fn_sum: 7.0000, cumulative_f1_score: 0.0935\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [58/64], Loss: 0.1655, tp_sum: 14.0000, fp_sum: 169.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1393\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [59/64], Loss: 0.2035, tp_sum: 23.0000, fp_sum: 163.0000, fn_sum: 5.0000, cumulative_f1_score: 0.2150\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [60/64], Loss: 0.1993, tp_sum: 14.0000, fp_sum: 179.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1302\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [61/64], Loss: 0.2041, tp_sum: 20.0000, fp_sum: 171.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1835\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [62/64], Loss: 0.1993, tp_sum: 17.0000, fp_sum: 170.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1611\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [63/64], Loss: 0.1580, tp_sum: 10.0000, fp_sum: 181.0000, fn_sum: 6.0000, cumulative_f1_score: 0.0966\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [2/5], Step [64/64], Loss: 0.2008, tp_sum: 14.0000, fp_sum: 168.0000, fn_sum: 10.0000, cumulative_f1_score: 0.1359\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [1/64], Loss: 0.1919, tp_sum: 14.0000, fp_sum: 168.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1373\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [2/64], Loss: 0.1424, tp_sum: 11.0000, fp_sum: 160.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1183\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [3/64], Loss: 0.1576, tp_sum: 16.0000, fp_sum: 176.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1524\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [4/64], Loss: 0.1677, tp_sum: 14.0000, fp_sum: 170.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1386\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [5/64], Loss: 0.2280, tp_sum: 23.0000, fp_sum: 175.0000, fn_sum: 9.0000, cumulative_f1_score: 0.2000\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [6/64], Loss: 0.1976, tp_sum: 10.0000, fp_sum: 172.0000, fn_sum: 11.0000, cumulative_f1_score: 0.0985\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [7/64], Loss: 0.2350, tp_sum: 28.0000, fp_sum: 153.0000, fn_sum: 7.0000, cumulative_f1_score: 0.2593\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [8/64], Loss: 0.1531, tp_sum: 13.0000, fp_sum: 175.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1275\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [9/64], Loss: 0.1947, tp_sum: 15.0000, fp_sum: 171.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1449\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [10/64], Loss: 0.2484, tp_sum: 25.0000, fp_sum: 164.0000, fn_sum: 8.0000, cumulative_f1_score: 0.2252\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [11/64], Loss: 0.1809, tp_sum: 16.0000, fp_sum: 164.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1584\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [12/64], Loss: 0.1707, tp_sum: 19.0000, fp_sum: 175.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1767\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [13/64], Loss: 0.1756, tp_sum: 16.0000, fp_sum: 175.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1517\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [14/64], Loss: 0.1964, tp_sum: 17.0000, fp_sum: 164.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1667\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [15/64], Loss: 0.1530, tp_sum: 17.0000, fp_sum: 160.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1735\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [16/64], Loss: 0.1444, tp_sum: 14.0000, fp_sum: 172.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1386\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [17/64], Loss: 0.1730, tp_sum: 10.0000, fp_sum: 179.0000, fn_sum: 8.0000, cumulative_f1_score: 0.0966\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [18/64], Loss: 0.1673, tp_sum: 16.0000, fp_sum: 176.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1509\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [19/64], Loss: 0.1708, tp_sum: 14.0000, fp_sum: 178.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1327\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [20/64], Loss: 0.1741, tp_sum: 19.0000, fp_sum: 179.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1727\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [21/64], Loss: 0.1750, tp_sum: 15.0000, fp_sum: 181.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1389\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [22/64], Loss: 0.1710, tp_sum: 13.0000, fp_sum: 176.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1250\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [23/64], Loss: 0.1804, tp_sum: 14.0000, fp_sum: 175.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1340\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [24/64], Loss: 0.1768, tp_sum: 14.0000, fp_sum: 185.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1284\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [25/64], Loss: 0.1672, tp_sum: 12.0000, fp_sum: 186.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1111\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [26/64], Loss: 0.1669, tp_sum: 12.0000, fp_sum: 176.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1165\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [27/64], Loss: 0.1984, tp_sum: 13.0000, fp_sum: 176.0000, fn_sum: 10.0000, cumulative_f1_score: 0.1226\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [28/64], Loss: 0.1841, tp_sum: 15.0000, fp_sum: 182.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1376\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [29/64], Loss: 0.1618, tp_sum: 13.0000, fp_sum: 169.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1300\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [30/64], Loss: 0.1946, tp_sum: 14.0000, fp_sum: 177.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1308\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [31/64], Loss: 0.1720, tp_sum: 17.0000, fp_sum: 156.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1753\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [32/64], Loss: 0.1917, tp_sum: 19.0000, fp_sum: 173.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1759\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [33/64], Loss: 0.1808, tp_sum: 14.0000, fp_sum: 179.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1315\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [34/64], Loss: 0.1766, tp_sum: 13.0000, fp_sum: 162.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1333\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [35/64], Loss: 0.1431, tp_sum: 12.0000, fp_sum: 171.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1212\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [36/64], Loss: 0.1955, tp_sum: 22.0000, fp_sum: 161.0000, fn_sum: 3.0000, cumulative_f1_score: 0.2115\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [37/64], Loss: 0.1881, tp_sum: 16.0000, fp_sum: 169.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1546\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [38/64], Loss: 0.2578, tp_sum: 21.0000, fp_sum: 164.0000, fn_sum: 14.0000, cumulative_f1_score: 0.1909\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [39/64], Loss: 0.1987, tp_sum: 15.0000, fp_sum: 165.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1471\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [40/64], Loss: 0.2233, tp_sum: 25.0000, fp_sum: 175.0000, fn_sum: 5.0000, cumulative_f1_score: 0.2174\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [41/64], Loss: 0.1281, tp_sum: 4.0000, fp_sum: 179.0000, fn_sum: 5.0000, cumulative_f1_score: 0.0417\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [42/64], Loss: 0.1985, tp_sum: 17.0000, fp_sum: 165.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1650\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [43/64], Loss: 0.1598, tp_sum: 17.0000, fp_sum: 175.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1611\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [44/64], Loss: 0.1807, tp_sum: 9.0000, fp_sum: 177.0000, fn_sum: 9.0000, cumulative_f1_score: 0.0882\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [45/64], Loss: 0.2060, tp_sum: 22.0000, fp_sum: 172.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1982\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [46/64], Loss: 0.1852, tp_sum: 14.0000, fp_sum: 173.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1340\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [47/64], Loss: 0.1765, tp_sum: 17.0000, fp_sum: 171.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1635\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [48/64], Loss: 0.2008, tp_sum: 22.0000, fp_sum: 161.0000, fn_sum: 6.0000, cumulative_f1_score: 0.2085\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [49/64], Loss: 0.1982, tp_sum: 16.0000, fp_sum: 176.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1481\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [50/64], Loss: 0.1629, tp_sum: 10.0000, fp_sum: 182.0000, fn_sum: 6.0000, cumulative_f1_score: 0.0962\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [51/64], Loss: 0.1685, tp_sum: 15.0000, fp_sum: 174.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1449\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [52/64], Loss: 0.1971, tp_sum: 14.0000, fp_sum: 179.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1296\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [53/64], Loss: 0.1516, tp_sum: 8.0000, fp_sum: 185.0000, fn_sum: 6.0000, cumulative_f1_score: 0.0773\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [54/64], Loss: 0.1430, tp_sum: 14.0000, fp_sum: 169.0000, fn_sum: 1.0000, cumulative_f1_score: 0.1414\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [55/64], Loss: 0.1836, tp_sum: 14.0000, fp_sum: 174.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1340\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [56/64], Loss: 0.1474, tp_sum: 8.0000, fp_sum: 185.0000, fn_sum: 6.0000, cumulative_f1_score: 0.0773\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [57/64], Loss: 0.1815, tp_sum: 14.0000, fp_sum: 167.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1400\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [58/64], Loss: 0.1869, tp_sum: 17.0000, fp_sum: 173.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1604\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [59/64], Loss: 0.1740, tp_sum: 13.0000, fp_sum: 174.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1256\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [60/64], Loss: 0.1921, tp_sum: 16.0000, fp_sum: 175.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1495\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [61/64], Loss: 0.2004, tp_sum: 24.0000, fp_sum: 169.0000, fn_sum: 3.0000, cumulative_f1_score: 0.2182\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [62/64], Loss: 0.1769, tp_sum: 14.0000, fp_sum: 175.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1340\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [63/64], Loss: 0.1865, tp_sum: 15.0000, fp_sum: 160.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1531\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [3/5], Step [64/64], Loss: 0.2017, tp_sum: 18.0000, fp_sum: 155.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1809\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [1/64], Loss: 0.2297, tp_sum: 20.0000, fp_sum: 163.0000, fn_sum: 10.0000, cumulative_f1_score: 0.1878\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [2/64], Loss: 0.1876, tp_sum: 18.0000, fp_sum: 165.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1748\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [3/64], Loss: 0.1755, tp_sum: 10.0000, fp_sum: 179.0000, fn_sum: 9.0000, cumulative_f1_score: 0.0962\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [4/64], Loss: 0.1647, tp_sum: 14.0000, fp_sum: 171.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1379\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [5/64], Loss: 0.1692, tp_sum: 14.0000, fp_sum: 177.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1340\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [6/64], Loss: 0.1853, tp_sum: 19.0000, fp_sum: 167.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1827\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [7/64], Loss: 0.2006, tp_sum: 20.0000, fp_sum: 166.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1896\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [8/64], Loss: 0.1769, tp_sum: 18.0000, fp_sum: 163.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1773\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [9/64], Loss: 0.1893, tp_sum: 16.0000, fp_sum: 170.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1538\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [10/64], Loss: 0.1940, tp_sum: 25.0000, fp_sum: 154.0000, fn_sum: 3.0000, cumulative_f1_score: 0.2415\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [11/64], Loss: 0.1614, tp_sum: 13.0000, fp_sum: 171.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1287\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [12/64], Loss: 0.1824, tp_sum: 11.0000, fp_sum: 176.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1063\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [13/64], Loss: 0.2226, tp_sum: 20.0000, fp_sum: 165.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1869\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [14/64], Loss: 0.1842, tp_sum: 16.0000, fp_sum: 163.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1592\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [15/64], Loss: 0.2146, tp_sum: 21.0000, fp_sum: 172.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1900\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [16/64], Loss: 0.1810, tp_sum: 14.0000, fp_sum: 171.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1366\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [17/64], Loss: 0.1914, tp_sum: 16.0000, fp_sum: 171.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1524\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [18/64], Loss: 0.1862, tp_sum: 18.0000, fp_sum: 177.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1659\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [19/64], Loss: 0.1558, tp_sum: 11.0000, fp_sum: 181.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1058\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [20/64], Loss: 0.1285, tp_sum: 8.0000, fp_sum: 186.0000, fn_sum: 2.0000, cumulative_f1_score: 0.0784\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [21/64], Loss: 0.1854, tp_sum: 14.0000, fp_sum: 168.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1379\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [22/64], Loss: 0.1804, tp_sum: 18.0000, fp_sum: 169.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1714\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [23/64], Loss: 0.1495, tp_sum: 12.0000, fp_sum: 172.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1206\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [24/64], Loss: 0.2014, tp_sum: 23.0000, fp_sum: 170.0000, fn_sum: 4.0000, cumulative_f1_score: 0.2091\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [25/64], Loss: 0.1882, tp_sum: 19.0000, fp_sum: 165.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1836\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [26/64], Loss: 0.1742, tp_sum: 18.0000, fp_sum: 174.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1690\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [27/64], Loss: 0.1641, tp_sum: 17.0000, fp_sum: 168.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1659\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [28/64], Loss: 0.1797, tp_sum: 13.0000, fp_sum: 168.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1294\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [29/64], Loss: 0.1737, tp_sum: 15.0000, fp_sum: 181.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1389\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [30/64], Loss: 0.1748, tp_sum: 14.0000, fp_sum: 169.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1386\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [31/64], Loss: 0.1452, tp_sum: 12.0000, fp_sum: 180.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1165\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [32/64], Loss: 0.1478, tp_sum: 14.0000, fp_sum: 176.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1353\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [33/64], Loss: 0.1123, tp_sum: 8.0000, fp_sum: 175.0000, fn_sum: 1.0000, cumulative_f1_score: 0.0833\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [34/64], Loss: 0.1348, tp_sum: 13.0000, fp_sum: 174.0000, fn_sum: 1.0000, cumulative_f1_score: 0.1294\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [35/64], Loss: 0.1565, tp_sum: 15.0000, fp_sum: 183.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1395\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [36/64], Loss: 0.1580, tp_sum: 15.0000, fp_sum: 171.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1471\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [37/64], Loss: 0.1487, tp_sum: 14.0000, fp_sum: 174.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1373\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [38/64], Loss: 0.2046, tp_sum: 19.0000, fp_sum: 164.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1818\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [39/64], Loss: 0.1970, tp_sum: 16.0000, fp_sum: 177.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1488\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [40/64], Loss: 0.2275, tp_sum: 16.0000, fp_sum: 164.0000, fn_sum: 10.0000, cumulative_f1_score: 0.1553\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [41/64], Loss: 0.1782, tp_sum: 13.0000, fp_sum: 163.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1327\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [42/64], Loss: 0.1715, tp_sum: 16.0000, fp_sum: 172.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1538\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [43/64], Loss: 0.1958, tp_sum: 11.0000, fp_sum: 179.0000, fn_sum: 10.0000, cumulative_f1_score: 0.1043\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [44/64], Loss: 0.1881, tp_sum: 17.0000, fp_sum: 172.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1604\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [45/64], Loss: 0.1995, tp_sum: 17.0000, fp_sum: 177.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1553\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [46/64], Loss: 0.2111, tp_sum: 22.0000, fp_sum: 162.0000, fn_sum: 6.0000, cumulative_f1_score: 0.2075\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [47/64], Loss: 0.2276, tp_sum: 19.0000, fp_sum: 174.0000, fn_sum: 11.0000, cumulative_f1_score: 0.1704\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [48/64], Loss: 0.1420, tp_sum: 12.0000, fp_sum: 171.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1212\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [49/64], Loss: 0.1923, tp_sum: 16.0000, fp_sum: 175.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1495\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [50/64], Loss: 0.1821, tp_sum: 14.0000, fp_sum: 170.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1366\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [51/64], Loss: 0.1987, tp_sum: 16.0000, fp_sum: 163.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1576\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [52/64], Loss: 0.1542, tp_sum: 14.0000, fp_sum: 178.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1346\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [53/64], Loss: 0.1886, tp_sum: 12.0000, fp_sum: 174.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1165\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [54/64], Loss: 0.1887, tp_sum: 15.0000, fp_sum: 177.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1395\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [55/64], Loss: 0.1971, tp_sum: 17.0000, fp_sum: 176.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1567\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [56/64], Loss: 0.1800, tp_sum: 15.0000, fp_sum: 182.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1376\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [57/64], Loss: 0.2150, tp_sum: 21.0000, fp_sum: 176.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1867\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [58/64], Loss: 0.1795, tp_sum: 19.0000, fp_sum: 167.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1827\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [59/64], Loss: 0.1654, tp_sum: 15.0000, fp_sum: 169.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1478\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [60/64], Loss: 0.1669, tp_sum: 15.0000, fp_sum: 169.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1478\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [61/64], Loss: 0.2018, tp_sum: 16.0000, fp_sum: 170.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1524\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [62/64], Loss: 0.1876, tp_sum: 17.0000, fp_sum: 187.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1498\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [63/64], Loss: 0.2023, tp_sum: 12.0000, fp_sum: 169.0000, fn_sum: 11.0000, cumulative_f1_score: 0.1176\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [4/5], Step [64/64], Loss: 0.1846, tp_sum: 17.0000, fp_sum: 171.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1619\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [1/64], Loss: 0.1928, tp_sum: 23.0000, fp_sum: 165.0000, fn_sum: 3.0000, cumulative_f1_score: 0.2150\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [2/64], Loss: 0.1766, tp_sum: 18.0000, fp_sum: 182.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1629\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [3/64], Loss: 0.1671, tp_sum: 12.0000, fp_sum: 175.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1171\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [4/64], Loss: 0.2016, tp_sum: 19.0000, fp_sum: 170.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1767\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [5/64], Loss: 0.1472, tp_sum: 12.0000, fp_sum: 173.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1200\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [6/64], Loss: 0.1922, tp_sum: 16.0000, fp_sum: 172.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1517\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [7/64], Loss: 0.2034, tp_sum: 22.0000, fp_sum: 156.0000, fn_sum: 6.0000, cumulative_f1_score: 0.2136\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [8/64], Loss: 0.2028, tp_sum: 16.0000, fp_sum: 182.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1435\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [9/64], Loss: 0.1272, tp_sum: 8.0000, fp_sum: 181.0000, fn_sum: 2.0000, cumulative_f1_score: 0.0804\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [10/64], Loss: 0.2033, tp_sum: 18.0000, fp_sum: 172.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1674\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [11/64], Loss: 0.1937, tp_sum: 16.0000, fp_sum: 162.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1592\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [12/64], Loss: 0.2695, tp_sum: 30.0000, fp_sum: 153.0000, fn_sum: 10.0000, cumulative_f1_score: 0.2691\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [13/64], Loss: 0.1774, tp_sum: 18.0000, fp_sum: 169.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1722\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [14/64], Loss: 0.2114, tp_sum: 21.0000, fp_sum: 163.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1981\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [15/64], Loss: 0.1466, tp_sum: 12.0000, fp_sum: 180.0000, fn_sum: 2.0000, cumulative_f1_score: 0.1165\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [16/64], Loss: 0.1888, tp_sum: 12.0000, fp_sum: 163.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1224\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [17/64], Loss: 0.1664, tp_sum: 12.0000, fp_sum: 178.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1154\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [18/64], Loss: 0.1653, tp_sum: 12.0000, fp_sum: 175.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1176\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [19/64], Loss: 0.1488, tp_sum: 10.0000, fp_sum: 178.0000, fn_sum: 4.0000, cumulative_f1_score: 0.0990\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [20/64], Loss: 0.2142, tp_sum: 21.0000, fp_sum: 170.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1927\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [21/64], Loss: 0.1700, tp_sum: 11.0000, fp_sum: 175.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1084\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [22/64], Loss: 0.2134, tp_sum: 18.0000, fp_sum: 162.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1748\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [23/64], Loss: 0.1810, tp_sum: 11.0000, fp_sum: 181.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1048\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [24/64], Loss: 0.1716, tp_sum: 12.0000, fp_sum: 174.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1176\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [25/64], Loss: 0.1687, tp_sum: 10.0000, fp_sum: 177.0000, fn_sum: 7.0000, cumulative_f1_score: 0.0980\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [26/64], Loss: 0.1594, tp_sum: 17.0000, fp_sum: 182.0000, fn_sum: 1.0000, cumulative_f1_score: 0.1567\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [27/64], Loss: 0.1410, tp_sum: 9.0000, fp_sum: 182.0000, fn_sum: 4.0000, cumulative_f1_score: 0.0882\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [28/64], Loss: 0.2074, tp_sum: 17.0000, fp_sum: 181.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1525\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [29/64], Loss: 0.2077, tp_sum: 19.0000, fp_sum: 166.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1792\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [30/64], Loss: 0.1926, tp_sum: 13.0000, fp_sum: 172.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1256\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [31/64], Loss: 0.1708, tp_sum: 14.0000, fp_sum: 172.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1366\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [32/64], Loss: 0.1203, tp_sum: 7.0000, fp_sum: 179.0000, fn_sum: 2.0000, cumulative_f1_score: 0.0718\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [33/64], Loss: 0.1749, tp_sum: 13.0000, fp_sum: 164.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1327\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [34/64], Loss: 0.1862, tp_sum: 15.0000, fp_sum: 164.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1493\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [35/64], Loss: 0.2263, tp_sum: 25.0000, fp_sum: 154.0000, fn_sum: 7.0000, cumulative_f1_score: 0.2370\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [36/64], Loss: 0.1832, tp_sum: 18.0000, fp_sum: 168.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1731\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [37/64], Loss: 0.1799, tp_sum: 14.0000, fp_sum: 174.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1346\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [38/64], Loss: 0.1934, tp_sum: 25.0000, fp_sum: 163.0000, fn_sum: 2.0000, cumulative_f1_score: 0.2326\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [39/64], Loss: 0.1916, tp_sum: 16.0000, fp_sum: 186.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1422\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [40/64], Loss: 0.1822, tp_sum: 13.0000, fp_sum: 169.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1281\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [41/64], Loss: 0.1656, tp_sum: 11.0000, fp_sum: 180.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1058\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [42/64], Loss: 0.2348, tp_sum: 24.0000, fp_sum: 161.0000, fn_sum: 7.0000, cumulative_f1_score: 0.2222\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [43/64], Loss: 0.1742, tp_sum: 17.0000, fp_sum: 165.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1675\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [44/64], Loss: 0.1690, tp_sum: 15.0000, fp_sum: 167.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1493\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [45/64], Loss: 0.2026, tp_sum: 22.0000, fp_sum: 167.0000, fn_sum: 6.0000, cumulative_f1_score: 0.2028\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [46/64], Loss: 0.2042, tp_sum: 18.0000, fp_sum: 166.0000, fn_sum: 8.0000, cumulative_f1_score: 0.1714\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [47/64], Loss: 0.1676, tp_sum: 15.0000, fp_sum: 174.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1435\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [48/64], Loss: 0.1883, tp_sum: 18.0000, fp_sum: 163.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1765\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [49/64], Loss: 0.1845, tp_sum: 15.0000, fp_sum: 181.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1389\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [50/64], Loss: 0.1832, tp_sum: 14.0000, fp_sum: 179.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1308\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [51/64], Loss: 0.1828, tp_sum: 13.0000, fp_sum: 181.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1221\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [52/64], Loss: 0.1780, tp_sum: 14.0000, fp_sum: 182.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1296\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [53/64], Loss: 0.1494, tp_sum: 12.0000, fp_sum: 175.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1188\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [54/64], Loss: 0.1602, tp_sum: 12.0000, fp_sum: 176.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1171\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [55/64], Loss: 0.2220, tp_sum: 21.0000, fp_sum: 167.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1927\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [56/64], Loss: 0.1673, tp_sum: 13.0000, fp_sum: 181.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1226\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [57/64], Loss: 0.1087, tp_sum: 4.0000, fp_sum: 189.0000, fn_sum: 2.0000, cumulative_f1_score: 0.0402\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [58/64], Loss: 0.1691, tp_sum: 21.0000, fp_sum: 161.0000, fn_sum: 1.0000, cumulative_f1_score: 0.2059\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [59/64], Loss: 0.1688, tp_sum: 16.0000, fp_sum: 164.0000, fn_sum: 3.0000, cumulative_f1_score: 0.1608\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [60/64], Loss: 0.1655, tp_sum: 13.0000, fp_sum: 175.0000, fn_sum: 5.0000, cumulative_f1_score: 0.1262\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [61/64], Loss: 0.1763, tp_sum: 15.0000, fp_sum: 169.0000, fn_sum: 4.0000, cumulative_f1_score: 0.1478\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [62/64], Loss: 0.2069, tp_sum: 16.0000, fp_sum: 167.0000, fn_sum: 9.0000, cumulative_f1_score: 0.1538\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [63/64], Loss: 0.1897, tp_sum: 18.0000, fp_sum: 174.0000, fn_sum: 6.0000, cumulative_f1_score: 0.1667\n",
      "torch.Size([32, 3, 224, 224])\n",
      "Epoch [5/5], Step [64/64], Loss: 0.1897, tp_sum: 16.0000, fp_sum: 167.0000, fn_sum: 7.0000, cumulative_f1_score: 0.1553\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n",
    "\n",
    "# Create a TensorBoard writer\n",
    "writer = SummaryWriter()\n",
    "model_name = \"custom_dnet_conf_1_14_original_v5\"\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 5\n",
    "lossMIN = 100000\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for i, (images, labels, _) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        print(images.shape)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # calculate statistics\n",
    "        # pred_labels = (nn.Softmax(dim=1)(outputs) > 1/14).long()\n",
    "        \n",
    "        tp_array = [0 for x in range(num_class)]\n",
    "        fp_array = [0 for x in range(num_class)]\n",
    "        fn_array = [0 for x in range(num_class)]\n",
    "        pred_labels = (outputs > 1/14).long()\n",
    "        tp_array += sum(torch.logical_and(pred_labels, labels))\n",
    "        fp_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), pred_labels))\n",
    "        fn_array += sum(torch.logical_and(torch.logical_xor(pred_labels, labels).long(), labels))\n",
    "        \n",
    "        writer.add_scalar('Loss/train', loss, epoch * len(train_loader) + i)\n",
    "        writer.add_scalar('TP_Sum/train', sum(tp_array), epoch * len(train_loader) + i)\n",
    "        writer.add_scalar('FP_Sum/train', sum(fp_array), epoch * len(train_loader) + i)\n",
    "        writer.add_scalar('FN_Sum/train', sum(fn_array), epoch * len(train_loader) + i)\n",
    "        writer.add_scalar('F1_Score/train', f1_score(sum(tp_array), sum(fp_array), sum(fn_array)), epoch * len(train_loader) + i)\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step(loss)\n",
    "\n",
    "        # Display\n",
    "        # if (i + 1) % 100 == 0:\n",
    "        print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, tp_sum: {:.4f}, fp_sum: {:.4f}, fn_sum: {:.4f}, cumulative_f1_score: {:.4f}\".format(epoch + 1, \\\n",
    "                                                                     n_epochs, \\\n",
    "                                                                     i + 1, \\\n",
    "                                                                     len(train_loader), \\\n",
    "                                                                     loss,\\\n",
    "                                                                     sum(tp_array), \\\n",
    "                                                                     sum(fp_array),\\\n",
    "                                                                     sum(fn_array),\\\n",
    "                                                                     f1_score(sum(tp_array), sum(fp_array), sum(fn_array))))\n",
    "        # print(\"outputs\\n\", outputs)\n",
    "        # print(\"pred_labels\\n\", pred_labels)\n",
    "        # print(\"actual labels\\n\", labels)\n",
    "\n",
    "        if loss < lossMIN:\n",
    "                lossMIN = loss    \n",
    "                torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, r'./dnet_models/m-' + model_name + '.pth.tar')\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, r'./dnet_models/m-' + model_name + '.pth.tar')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom_dnet_conf_1_14_original_v5'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def to_tensor(crops):\n",
    "    return torch.stack([transforms.ToTensor()(crop) for crop in crops])\n",
    "\n",
    "def normalize_crops(crops):\n",
    "    normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    normalized_crops = []\n",
    "    for crop in crops:\n",
    "        normalized_crop = normalize(crop)  # Assuming normalize is a function you have defined\n",
    "        normalized_crops.append(normalized_crop)\n",
    "    return torch.stack(normalized_crops)\n",
    "\n",
    "def computeAUROC (dataGT, dataPRED, classCount):\n",
    "    \n",
    "    outAUROC = []\n",
    "    \n",
    "    datanpGT = dataGT.cpu().numpy()\n",
    "    datanpPRED = dataPRED.cpu().numpy()\n",
    "    \n",
    "    for i in range(classCount):\n",
    "        outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "        \n",
    "    return outAUROC\n",
    "\n",
    "def test (pathDirData, pathFileTest, pathModel, nnClassCount, trBatchSize, transResize, transCrop):   \n",
    "        \n",
    "        CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "        \n",
    "        model = dense_net(14, training=False)\n",
    "        modelCheckpoint = torch.load(pathModel)\n",
    "        model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "        model.to(device)\n",
    "\n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS\n",
    "        transformList = []\n",
    "        transformList.append(transforms.Resize(transResize))\n",
    "        transformList.append(transforms.TenCrop(transCrop))\n",
    "\n",
    "        transformList.append(to_tensor)\n",
    "        # transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "        transformList.append(normalize_crops)\n",
    "        # transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "        datasetTest = DatasetGenerator(pathImageDirectory=pathDirData, pathDatasetFile=pathFileTest, transform=transformSequence)\n",
    "        dataLoaderTest = DataLoader(dataset=datasetTest, batch_size=trBatchSize, num_workers=0, shuffle=False, pin_memory=True)\n",
    "        \n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "        model.eval()\n",
    "        print('before enumeration begins')\n",
    "        for i, (input, target, _) in enumerate(dataLoaderTest):\n",
    "            # print(i)\n",
    "            target = target.cuda()\n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            \n",
    "            bs, n_crops, c, h, w = input.size()\n",
    "            with torch.no_grad():\n",
    "                varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda())\n",
    "            \n",
    "                out = model(varInput)\n",
    "                outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "                \n",
    "                outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "        aurocIndividual = computeAUROC(outGT, outPRED, nnClassCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "        print ('AUROC mean ', aurocMean)\n",
    "        \n",
    "        for i in range (0, len(aurocIndividual)):\n",
    "            print (CLASS_NAMES[i], ' ', aurocIndividual[i])\n",
    "        \n",
    "     \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n",
      "Collected 2048 images from ../chexnet/dataset/test_1.txt\n",
      "before enumeration begins\n",
      "AUROC mean  0.5095133236789442\n",
      "Atelectasis   0.6075298180088441\n",
      "Cardiomegaly   0.41596002329930415\n",
      "Effusion   0.4868496283590623\n",
      "Infiltration   0.579702051402635\n",
      "Mass   0.5511618939038294\n",
      "Nodule   0.5636917286354667\n",
      "Pneumonia   0.4135702135702136\n",
      "Pneumothorax   0.44408713692946056\n",
      "Consolidation   0.6018611670020121\n",
      "Edema   0.5701375164690382\n",
      "Emphysema   0.4491948063360942\n",
      "Fibrosis   0.46562888768381766\n",
      "Pleural_Thickening   0.5488754479329186\n",
      "Hernia   0.4349362119725221\n"
     ]
    }
   ],
   "source": [
    "test (pathDirData = pathDirData, \n",
    "      pathFileTest = r'../chexnet/dataset/test_1.txt', \n",
    "      pathModel = f'./dnet_models/m-{model_name}.pth.tar', \n",
    "      nnClassCount = 14, \n",
    "      trBatchSize = trBatchSize, \n",
    "      transResize = transResize, \n",
    "      transCrop = transCrop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
