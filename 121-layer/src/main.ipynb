{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import densenet121\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self,data_dir, label_file, transform=None):\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.labels_df = pd.read_excel(label_file)\n",
    "        #if label contains Pneumothorax = 1 else 0 \n",
    "        self.labels_df['Pneumothorax'] = self.labels_df['Finding Labels'].apply(lambda x: 1 if 'Pneumothorax' in x.split('|') else 0)\n",
    "        self.image_paths = {os.path.basename(x): x for x in glob.glob(os.path.join(data_dir, '*', 'images', '*.png'))}\n",
    "        self.labels_df['path'] = self.labels_df['Image Index'].map(self.image_paths.get)\n",
    "        self.labels_df.dropna(subset=['path'], inplace=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels_df.iloc[idx]['path']\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.labels_df.iloc[idx]['Pneumothorax']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def get_transforms():  \n",
    "#resize the image size to 224 x 224 pixels\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def get_data_loaders(data_dir, label_file, batch_size=32, val_split=0.2,  test_split=0.1):\n",
    "\n",
    "    transform = get_transforms()\n",
    "    dataset = PneumoniaDataset(data_dir=data_dir, label_file=label_file, transform=transform)\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    val_size = int(val_split * len(dataset))\n",
    "    test_size = int(test_split * len(dataset))\n",
    "    train_size = len(dataset) - val_size - test_size\n",
    "    \n",
    "    # Split the dataset into training, validation, and test sets\n",
    "    train_dataset, val_test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size + test_size])\n",
    "    val_dataset, test_dataset = torch.utils.data.random_split(val_test_dataset, [val_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_dataset, val_dataset,train_loader, val_loader,test_dataset,test_loader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Size: 3501\n",
      "Validation Dataset Size: 999\n",
      "Test Dataset Size: 499\n",
      "Training DataLoader Batches: 110\n",
      "Validation DataLoader Batches: 32\n",
      "Test DataLoader Batches: 16\n",
      "Training DataLoader:\n",
      "Batch Images Shape: torch.Size([32, 3, 224, 224])\n",
      "Batch Labels Shape: torch.Size([32])\n",
      "Batch Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "Validation DataLoader:\n",
      "Batch Images Shape: torch.Size([32, 3, 224, 224])\n",
      "Batch Labels Shape: torch.Size([32])\n",
      "Batch Labels: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "Test DataLoader:\n",
      "Batch Images Shape: torch.Size([32, 3, 224, 224])\n",
      "Batch Labels Shape: torch.Size([32])\n",
      "Batch Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset, val_dataset,train_loader, val_loader,test_dataset, test_loader= get_data_loaders(data_dir='../../raw_data/archive/', label_file='../../raw_data/archive/CXR8-selected/micro.xlsx')\n",
    "print(f\"Training Dataset Size: {len(train_dataset)}\")\n",
    "print(f\"Validation Dataset Size: {len(val_dataset)}\")\n",
    "print(f\"Test Dataset Size: {len(test_dataset)}\")\n",
    "\n",
    "def count_batches(data_loader):\n",
    "    return sum(1 for _ in data_loader)\n",
    "\n",
    "print(f\"Training DataLoader Batches: {count_batches(train_loader)}\")\n",
    "print(f\"Validation DataLoader Batches: {count_batches(val_loader)}\")\n",
    "print(f\"Test DataLoader Batches: {count_batches(test_loader)}\")\n",
    "\n",
    "def inspect_loader(data_loader):\n",
    "    images, labels = next(iter(data_loader))\n",
    "    print(f\"Batch Images Shape: {images.shape}\")\n",
    "    print(f\"Batch Labels Shape: {labels.shape}\")\n",
    "    print(f\"Batch Labels: {labels}\")\n",
    "\n",
    "# Inspect each DataLoader\n",
    "print(\"Training DataLoader:\")\n",
    "inspect_loader(train_loader)\n",
    "\n",
    "print(\"\\nValidation DataLoader:\")\n",
    "inspect_loader(val_loader)\n",
    "\n",
    "print(\"\\nTest DataLoader:\")\n",
    "inspect_loader(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DensenNet121\n",
    "model = densenet121(weights='DenseNet121_Weights.DEFAULT')\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(500, 1),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Epoch 0/9, Loss: 0.07990026066329259, Acc: 0.9885746929448729\n",
      "Epoch 2/10\n",
      "----------\n",
      "Epoch 1/9, Loss: 0.043374007464017025, Acc: 0.9885746929448729\n",
      "Epoch 3/10\n",
      "----------\n",
      "Epoch 2/9, Loss: 0.023513220813895754, Acc: 0.9885746929448729\n",
      "Epoch 4/10\n",
      "----------\n",
      "Epoch 3/9, Loss: 0.007953736617718551, Acc: 0.9985718366181091\n",
      "Epoch 5/10\n",
      "----------\n",
      "Epoch 4/9, Loss: 0.022046017459793493, Acc: 0.9925735504141674\n",
      "Epoch 6/10\n",
      "----------\n",
      "Epoch 5/9, Loss: 0.013139387878574169, Acc: 0.9962867752070836\n",
      "Epoch 7/10\n",
      "----------\n",
      "Epoch 6/9, Loss: 0.0018234844873002253, Acc: 0.9994287346472437\n",
      "Epoch 8/10\n",
      "----------\n",
      "Epoch 7/9, Loss: 0.0006018527172530728, Acc: 1.0\n",
      "Epoch 9/10\n",
      "----------\n",
      "Epoch 8/9, Loss: 0.0002889940288236307, Acc: 1.0\n",
      "Epoch 10/10\n",
      "----------\n",
      "Epoch 9/9, Loss: 0.00014511467454472095, Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            # Clear previous gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            preds = torch.round(outputs)\n",
    "            total_correct += torch.sum(preds == labels.unsqueeze(1).data)\n",
    "\n",
    "        epoch_loss = total_loss / len(train_dataset)\n",
    "        epoch_acc = total_correct.double() / len(train_dataset)\n",
    "\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss}, Acc: {epoch_acc}')\n",
    "\n",
    "train_model(model, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.40%\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SUTD 8\\50.039 Theory and Practice of Deep Learning\\DeepLearningProject\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9839679358717435, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model, data_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    # No need to track gradients for testing\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            pred_labels.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels)\n",
    "    recall = recall_score(true_labels, pred_labels)\n",
    "    f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "    \n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Call the evaluate function\n",
    "test_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
